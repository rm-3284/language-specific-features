{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Features Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_dir = Path().resolve().parent\n",
    "statistic_dir = project_dir / \"statistics\"\n",
    "script_dir = project_dir / \"scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(script_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from visualization import (\n",
    "    plot_all_layers,\n",
    "    plot_all_lang_feature_overlap,\n",
    "    plot_lang_feature_overlap_trend,\n",
    "    plot_all_co_occurrence,\n",
    "    plot_all_cross_co_occurrence,\n",
    "    plot_all_count_box_plots,\n",
    "    plot_lape_result,\n",
    "    plot_umap,\n",
    "    plot_ppl_change_matrix,\n",
    "    generate_ppl_change_matrix,\n",
    "    plot_metrics,\n",
    "    plot_features_similarity,\n",
    "    plot_sae_features_entropy_score_correlation,\n",
    "    plot_intersection_heatmap,\n",
    "    plot_iou_heatmap,\n",
    "    plot_shared_count_bar_chart,\n",
    "    plot_fastext_vs_sae_metrics,\n",
    "    plot_entropy_distribution,\n",
    ")\n",
    "\n",
    "from feature_visualizer import (\n",
    "    generate_feature_activations_visualization,\n",
    ")\n",
    "\n",
    "from loader import (\n",
    "    load_layer_to_summary,\n",
    "    load_lang_to_dataset_token_activations,\n",
    "    load_lang_to_dataset_token_activations_aggregate,\n",
    "    load_all_interpretations,\n",
    "    load_sae_features_info_df,\n",
    "    load_lang_to_sae_features_info,\n",
    ")\n",
    "\n",
    "from const import (\n",
    "    lang_choices_to_qualified_name, \n",
    "    layer_to_index, \n",
    "    lang_choices_to_qualified_name,\n",
    "    lang_choices_to_iso639_1,\n",
    "    hookpoint_to_layer,\n",
    "    lang_choices_to_flores,\n",
    "    )\n",
    "\n",
    "from delphi.log.result_analysis import get_metrics_per_latent, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.2-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_xnli = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"facebook/xnli\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"hi\",\n",
    "        \"es\",\n",
    "        \"th\",\n",
    "        \"bg\",\n",
    "        \"ru\",\n",
    "        \"tr\",\n",
    "        \"vi\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_pawsx = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"google-research-datasets/paws-x\",\n",
    "    \"split\": \"train\",\n",
    "    \"languages\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"es\",\n",
    "        \"ja\",\n",
    "        \"ko\",\n",
    "        \"zh\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_flores = {\n",
    "    \"model\": \"meta-llama/Llama-3.2-1B\",\n",
    "    \"sae\": {\n",
    "        \"model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",\n",
    "        \"num_latents\": 131072,\n",
    "    },\n",
    "    \"dataset\": \"openlanguagedata/flores_plus\",\n",
    "    \"split\": \"dev\",\n",
    "    \"languages\": [\n",
    "        \"eng_Latn\",\n",
    "        \"deu_Latn\",\n",
    "        \"fra_Latn\",\n",
    "        \"ita_Latn\",\n",
    "        \"por_Latn\",\n",
    "        \"hin_Deva\",\n",
    "        \"spa_Latn\",\n",
    "        \"tha_Thai\",\n",
    "        \"bul_Cyrl\",\n",
    "        \"rus_Cyrl\",\n",
    "        \"tur_Latn\",\n",
    "        \"vie_Latn\",\n",
    "        \"jpn_Jpan\",\n",
    "        \"kor_Hang\",\n",
    "        \"cmn_Hans\",\n",
    "    ],\n",
    "    \"layers\": [\n",
    "        \"model.layers.0.mlp\",\n",
    "        \"model.layers.1.mlp\",\n",
    "        \"model.layers.2.mlp\",\n",
    "        \"model.layers.3.mlp\",\n",
    "        \"model.layers.4.mlp\",\n",
    "        \"model.layers.5.mlp\",\n",
    "        \"model.layers.6.mlp\",\n",
    "        \"model.layers.7.mlp\",\n",
    "        \"model.layers.8.mlp\",\n",
    "        \"model.layers.9.mlp\",\n",
    "        \"model.layers.10.mlp\",\n",
    "        \"model.layers.11.mlp\",\n",
    "        \"model.layers.12.mlp\",\n",
    "        \"model.layers.13.mlp\",\n",
    "        \"model.layers.14.mlp\",\n",
    "        \"model.layers.15.mlp\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_summary_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")\n",
    "\n",
    "df_layers_llama_xnli = load_layer_to_summary(\n",
    "    data_path_summary_xnli, config_xnli[\"layers\"], config_xnli[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_xnli, config_xnli, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_xnli, config_xnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_xnli = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    config_xnli[\"layers\"],\n",
    "    config_xnli[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_xnli.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_facebook_xnli.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_pawsx = load_layer_to_summary(\n",
    "    data_path_pawsx, config_pawsx[\"layers\"], config_pawsx[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(df_layers_llama_pawsx, config_pawsx, range_y=[0, 40_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_pawsx, config_pawsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    config_pawsx[\"layers\"],\n",
    "    config_pawsx[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_pawsx.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_google-research-datasets_paws-x.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli, config_xnli, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLORES+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layers_llama_flores = load_layer_to_summary(\n",
    "    data_path_flores, config_flores[\"layers\"], config_flores[\"languages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_layers(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_lang_feature_overlap(\n",
    "    df_layers_llama_flores, config_flores, range_y=[0, 40_000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lang_feature_overlap_trend(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_co_occurrence(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_count_box_plots(df_layers_llama_flores, config_flores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "df_dataset_token_activations_flores = load_lang_to_dataset_token_activations_aggregate(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    config_flores[\"layers\"],\n",
    "    config_flores[\"languages\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_token_activations_flores.rename(\n",
    "    columns={\n",
    "        \"index\": \"sae_feature_number\",\n",
    "        \"count\": \"token_count\",\n",
    "    }\n",
    ").to_csv(\"sae_features_gsarti_flores_101.csv\", index=False, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flores-101 with XNLI and PAWS-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_xnli, config_xnli\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_xnli,\n",
    "    config_xnli,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores, config_flores, df_layers_llama_pawsx, config_pawsx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_cross_co_occurrence(\n",
    "    df_layers_llama_flores,\n",
    "    config_flores,\n",
    "    df_layers_llama_pawsx,\n",
    "    config_pawsx,\n",
    "    specific_feature_lang_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Index Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_xnli[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "\n",
    "out_path = project_dir / \"visualization\" / \"feature_index\" / model / sae_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_index = 25\n",
    "layer = \"model.layers.0.mlp\"\n",
    "\n",
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "layers = config_flores[\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    layer,\n",
    "    config_xnli[\"languages\"],\n",
    "    [25, 100],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_xnli,\n",
    "    layer,\n",
    "    config_xnli[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_pawsx = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_pawsx,\n",
    "    layer,\n",
    "    config_pawsx[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "lang_to_dataset_token_activations_flores = load_lang_to_dataset_token_activations(\n",
    "    data_path_dataset_token_activations_flores,\n",
    "    layer,\n",
    "    config_flores[\"languages\"],\n",
    "    [feature_index],\n",
    ")\n",
    "\n",
    "dataset_lang_to_dataset_token_activations = {\n",
    "    \"xnli\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "        \"config\": {**config_xnli},\n",
    "    },\n",
    "    \"paws-x\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "        \"config\": {**config_pawsx},\n",
    "    },\n",
    "    \"flores\": {\n",
    "        \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "        \"config\": {**config_flores},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = {\n",
    "    \"feature_index\": feature_index,\n",
    "    \"layer\": layer,\n",
    "    \"lang\": \"None\",\n",
    "    \"selected_prob\": \"-\",\n",
    "    \"entropy\": \"-\",\n",
    "    \"interpretation\": \"-\",\n",
    "    \"metrics\": [\n",
    "        {\n",
    "            \"score_type\": \"-\",\n",
    "            \"true_positives\": \"-\",\n",
    "            \"true_negatives\": \"-\",\n",
    "            \"false_positives\": \"-\",\n",
    "            \"false_negatives\": \"-\",\n",
    "            \"total_examples\": \"-\",\n",
    "            \"total_positives\": \"-\",\n",
    "            \"total_negatives\": \"-\",\n",
    "            \"failed_count\": \"-\",\n",
    "            \"precision\": \"-\",\n",
    "            \"recall\": \"-\",\n",
    "            \"f1_score\": \"-\",\n",
    "            \"accuracy\": \"-\",\n",
    "            \"true_positive_rate\": \"-\",\n",
    "            \"true_negative_rate\": \"-\",\n",
    "            \"false_positive_rate\": \"-\",\n",
    "            \"false_negative_rate\": \"-\",\n",
    "            \"positive_class_ratio\": \"-\",\n",
    "            \"negative_class_ratio\": \"-\",\n",
    "            \"auc\": None,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "generate_feature_activations_visualization(\n",
    "    dataset_lang_to_dataset_token_activations,\n",
    "    feature_index,\n",
    "    feature_info,\n",
    "    model,\n",
    "    layer,\n",
    "    sae_model,\n",
    "    out_path,\n",
    "    lang_choices_to_qualified_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_10_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_10_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_top_10_result = torch.load(lape_top_10_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_top_10_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_10_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-10 Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_neuron_result_path = (\n",
    "    project_dir / \"mlp_acts_specific\" / config_xnli[\"model\"] / \"lape_neuron.pt\"\n",
    ")\n",
    "\n",
    "lape_neuron_result = torch.load(lape_neuron_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_neuron_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/lape_neuron\"\n",
    "    ),\n",
    "    title=\"Distribution of Language-specific Neurons\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_entropy.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(\n",
    "    lape_top_1_per_layer_result_path, weights_only=False\n",
    ")\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_entropy\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_top_1_per_layer_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_top_1_per_layer_by_freq.pt\"\n",
    ")\n",
    "\n",
    "lape_result_top_1_per_layer = torch.load(\n",
    "    lape_top_1_per_layer_result_path, weights_only=False\n",
    ")\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_result_top_1_per_layer,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_top_1_per_layer_by_freq\"\n",
    "    ),\n",
    "    title=\"Distribution of Top-1 per Layer Language-Specific Features by Frequency\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)\n",
    "\n",
    "plot_lape_result(\n",
    "    lape_all_result,\n",
    "    out_dir=Path(\n",
    "        r\"visualization/lape/meta-llama/Llama-3.2-1B/EleutherAI/sae-Llama-3.2-1B-131k/sae_features/lape_all\"\n",
    "    ),\n",
    "    title=\"Distribution of LAPE for all Language-Specific Features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language-Specific Features Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_metrics_to_nested_dict(df):\n",
    "    result = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        layer = row[\"layer\"]\n",
    "        latent_idx = row[\"latent_idx\"]\n",
    "        values = row.drop([\"layer\", \"latent_idx\"])\n",
    "        values = values.apply(lambda x: round(x, 3) if isinstance(x, float) else x)\n",
    "\n",
    "        layer_key = f\"model.{layer}\"\n",
    "\n",
    "        if layer_key not in result:\n",
    "            result[layer_key] = {}\n",
    "        if latent_idx not in result[layer_key]:\n",
    "            result[layer_key][latent_idx] = []\n",
    "\n",
    "        result[layer_key][latent_idx].append(values.to_dict())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_folder = project_dir / \"interpret_sae_features\" / \"explanations\"\n",
    "\n",
    "scores_path = project_dir / \"interpret_sae_features\" / \"scores\"\n",
    "\n",
    "visualize_path = project_dir / \"visualization\" / \"interpret_sae_features\" / \"scores\"\n",
    "\n",
    "hookpoints = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretations = load_all_interpretations(interpretation_folder)\n",
    "latent_df, counts = load_data(scores_path, hookpoints)\n",
    "df_metrics = get_metrics_per_latent(latent_df)\n",
    "metrics = convert_df_metrics_to_nested_dict(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_flores[\"model\"]\n",
    "sae_model = config_flores[\"sae\"][\"model\"]\n",
    "model_name = config_flores[\"model\"].split(\"/\")[-1]\n",
    "sae_model_name = config_flores[\"sae\"][\"model\"].split(\"/\")[-1]\n",
    "layers = config_flores[\"layers\"]\n",
    "\n",
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "for lang in tqdm(sorted_lang, desc=\"Processing languages\"):\n",
    "    lang_index = sorted_lang.index(lang)\n",
    "\n",
    "    for layer in tqdm(layers, desc=\"Processing layers\", leave=False):\n",
    "        layer_index = layer_to_index[layer]\n",
    "        lang_final_indices = lape_all_result[\"final_indice\"][lang_index][\n",
    "            layer_index\n",
    "        ].tolist()\n",
    "\n",
    "        if len(lang_final_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        layer = layers[layer_index]\n",
    "\n",
    "        lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "            data_path_dataset_token_activations_xnli,\n",
    "            layer,\n",
    "            config_xnli[\"languages\"],\n",
    "            lang_final_indices,\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_pawsx = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_pawsx,\n",
    "                layer,\n",
    "                config_pawsx[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        lang_to_dataset_token_activations_flores = (\n",
    "            load_lang_to_dataset_token_activations(\n",
    "                data_path_dataset_token_activations_flores,\n",
    "                layer,\n",
    "                config_flores[\"languages\"],\n",
    "                lang_final_indices,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        dataset_lang_to_dataset_token_activations = {\n",
    "            \"xnli\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_xnli,\n",
    "                \"config\": {**config_xnli},\n",
    "            },\n",
    "            \"paws-x\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_pawsx,\n",
    "                \"config\": {**config_pawsx},\n",
    "            },\n",
    "            \"flores\": {\n",
    "                \"dataset_token_activations\": lang_to_dataset_token_activations_flores,\n",
    "                \"config\": {**config_flores},\n",
    "            },\n",
    "        }\n",
    "\n",
    "        out_path = (\n",
    "            project_dir\n",
    "            / \"visualization\"\n",
    "            / \"feature_index\"\n",
    "            / model_name\n",
    "            / sae_model_name\n",
    "            / layer\n",
    "            / lang\n",
    "        )\n",
    "\n",
    "        selected_probs = lape_all_result[\"features_info\"][lang][\"selected_probs\"]\n",
    "        entropies = lape_all_result[\"features_info\"][lang][\"entropies\"]\n",
    "\n",
    "        for feature_index in tqdm(\n",
    "            lang_final_indices, desc=\"Processing indices\", leave=False\n",
    "        ):\n",
    "            try:\n",
    "                file_path = out_path / f\"feature_{feature_index}.html\"\n",
    "\n",
    "                if file_path.exists():\n",
    "                    continue\n",
    "\n",
    "                arg_index = lape_all_result[\"features_info\"][lang][\"indicies\"].index(\n",
    "                    (layer_index, feature_index)\n",
    "                )\n",
    "\n",
    "                feature_info = {\n",
    "                    \"feature_index\": feature_index,\n",
    "                    \"layer\": layer,\n",
    "                    \"lang\": lang,\n",
    "                    \"selected_prob\": round(selected_probs[arg_index].item(), ndigits=3),\n",
    "                    \"entropy\": round(entropies[arg_index].item(), ndigits=3),\n",
    "                    \"interpretation\": interpretations[layer][feature_index],\n",
    "                    \"metrics\": metrics[layer][feature_index],\n",
    "                }\n",
    "\n",
    "                generate_feature_activations_visualization(\n",
    "                    dataset_lang_to_dataset_token_activations,\n",
    "                    feature_index,\n",
    "                    feature_info,\n",
    "                    model,\n",
    "                    layer,\n",
    "                    sae_model,\n",
    "                    out_path,\n",
    "                    lang_choices_to_qualified_name,\n",
    "                    examples_per_section=40,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {lang} - {layer} - {feature_index}\")\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"umap\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = config_xnli[\"model\"]\n",
    "sae_model = config_xnli[\"sae\"][\"model\"]\n",
    "layers = config_xnli[\"layers\"]\n",
    "\n",
    "plot_umap(lape_all_result, layers, model, sae_model, umap_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ppl_output_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"normal\"\n",
    "    / \"ppl.pt\"\n",
    ")\n",
    "\n",
    "normal_ppl_result = torch.load(normal_ppl_output_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"fixed_0\"\n",
    ")\n",
    "\n",
    "intervened_neuron_ppl_results = {\n",
    "    lang_choices_to_qualified_name[intervened_lang]: torch.load(\n",
    "        out_path / f\"ppl_{intervened_lang}.pt\", weights_only=False\n",
    "    )\n",
    "    for intervened_lang in config_flores[\"languages\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"fixed_0\"\n",
    "    / \"ppl_change_matrix.html\"\n",
    ")\n",
    "\n",
    "plot_ppl_change_matrix(\n",
    "    config_flores[\"languages\"],\n",
    "    normal_ppl_result,\n",
    "    intervened_neuron_ppl_results,\n",
    "    out_path,\n",
    "    title=\"PPL Change Matrix for Neuron Interventions\",\n",
    "    num_examples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"plus_0.1\",\n",
    "    \"plus_0.2\",\n",
    "    \"plus_0.3\",\n",
    "    \"plus_0.4\",\n",
    "    \"min_0.1\",\n",
    "    \"min_0.2\",\n",
    "    \"min_0.3\",\n",
    "    \"min_0.4\",\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    out_path = (\n",
    "        project_dir\n",
    "        / \"ppl\"\n",
    "        / config_flores[\"model\"]\n",
    "        / config_flores[\"dataset\"]\n",
    "        / \"neuron_intervention\"\n",
    "        / \"baseline\"\n",
    "        / config\n",
    "    )\n",
    "\n",
    "    intervened_neuron_ppl_results = {\n",
    "        lang_choices_to_qualified_name[intervened_lang]: torch.load(\n",
    "            out_path / f\"ppl_{intervened_lang}.pt\", weights_only=False\n",
    "        )\n",
    "        for intervened_lang in config_flores[\"languages\"]\n",
    "    }\n",
    "\n",
    "    out_path = (\n",
    "        project_dir\n",
    "        / \"visualization\"\n",
    "        / \"ppl\"\n",
    "        / config_flores[\"model\"]\n",
    "        / config_flores[\"dataset\"]\n",
    "        / \"neuron_intervention\"\n",
    "        / \"baseline\"\n",
    "        / config\n",
    "        / \"ppl_change_matrix.html\"\n",
    "    )\n",
    "\n",
    "    plot_ppl_change_matrix(\n",
    "        config_flores[\"languages\"],\n",
    "        normal_ppl_result,\n",
    "        intervened_neuron_ppl_results,\n",
    "        out_path,\n",
    "        title=\"PPL Change Matrix for Neuron Interventions\",\n",
    "        num_examples=1000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"baseline\"\n",
    "    / \"min_0_2\"\n",
    ")\n",
    "\n",
    "intervened_neuron_ppl_results = {\n",
    "    lang_choices_to_qualified_name[intervened_lang]: torch.load(\n",
    "        out_path / f\"ppl_{intervened_lang}.pt\", weights_only=False\n",
    "    )\n",
    "    for intervened_lang in config_flores[\"languages\"]\n",
    "}\n",
    "\n",
    "out_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"neuron_intervention\"\n",
    "    / \"baseline\"\n",
    "    / \"min_0_2\"\n",
    "    / \"ppl_change_matrix.html\"\n",
    ")\n",
    "\n",
    "plot_ppl_change_matrix(\n",
    "    config_flores[\"languages\"],\n",
    "    normal_ppl_result,\n",
    "    intervened_neuron_ppl_results,\n",
    "    out_path,\n",
    "    title=\"PPL Change Matrix for Neuron Interventions\",\n",
    "    num_examples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAE Feature Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"sae_intervention\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    \"top_10/entropy/max/mult_0.2\",\n",
    "    \"top_10/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_1\",\n",
    "    \"top_1_per_layer/entropy/avg/mult_-1\",\n",
    "    \"top_1_per_layer/entropy/max/mult_0.2\",\n",
    "    \"top_1_per_layer/entropy/max/mult_-0.2\",\n",
    "    \"top_1_per_layer/freq/avg/mult_-1\",\n",
    "    \"all/entropy/max/mult_0.1\",\n",
    "    \"all/entropy/max/mult_0.2\",\n",
    "    \"all/entropy/max/mult_0.3\",\n",
    "    \"all/entropy/max/mult_0.4\",\n",
    "    \"all/entropy/max/mult_-0.1\",\n",
    "    \"all/entropy/max/mult_-0.2\",\n",
    "    \"all/entropy/max/mult_-0.3\",\n",
    "    \"all/entropy/max/mult_-0.4\",\n",
    "]\n",
    "\n",
    "generate_ppl_change_matrix(\n",
    "    configs,\n",
    "    config_flores[\"model\"],\n",
    "    config_flores[\"dataset\"],\n",
    "    config_flores[\"languages\"],\n",
    "    in_path,\n",
    "    normal_ppl_result,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_path = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"sae-count\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "\n",
    "sae_based_lid_metric = json.load(open(metric_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastext_classifier_metric = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"fasttext\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "fastext_classifier_metric = json.load(open(fastext_classifier_metric, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_based_lid_metric = (\n",
    "    project_dir\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"neuron-count\"\n",
    "    / \"metrics.json\"\n",
    ")\n",
    "neuron_based_lid_metric = json.load(open(neuron_based_lid_metric, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    ")\n",
    "\n",
    "plot_fastext_vs_sae_metrics(\n",
    "    sae_based_lid_metric,\n",
    "    fastext_classifier_metric,\n",
    "    neuron_based_lid_metric,\n",
    "    output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"sae-count\"\n",
    ")\n",
    "\n",
    "plot_metrics(sae_based_lid_metric, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"classification\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"MartinThoma\"\n",
    "    / \"wili_2018\"\n",
    "    / \"neuron-count\"\n",
    ")\n",
    "\n",
    "plot_metrics(neuron_based_lid_metric, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data from both tables\n",
    "data_lower = {\n",
    "    \"Language\": [\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"it\",\n",
    "        \"pt\",\n",
    "        \"hi\",\n",
    "        \"es\",\n",
    "        \"th\",\n",
    "        \"bg\",\n",
    "        \"ru\",\n",
    "        \"tr\",\n",
    "        \"vi\",\n",
    "        \"ja\",\n",
    "        \"ko\",\n",
    "        \"zh\",\n",
    "    ],\n",
    "    \"Alpha\": [\n",
    "        0.4,\n",
    "        0.3,\n",
    "        0.4,\n",
    "        0.2,\n",
    "        0.175,\n",
    "        0.5,\n",
    "        0.375,\n",
    "        0.4,\n",
    "        0.5,\n",
    "        0.25,\n",
    "        0.3,\n",
    "        0.3,\n",
    "        0.4,\n",
    "        0.3,\n",
    "    ],\n",
    "    \"Change_Count\": [17, 29, 10, 17, 29, 42, 18, 8, 27, 16, 11, 9, 16, 28],\n",
    "    \"Change_Incoherent\": [0, 0, 3, 0, 19, 0, 6, 0, 2, 1, 0, 4, 4, 1],\n",
    "    \"Change_Partially_Coherent\": [3, 15, 4, 7, 7, 10, 12, 5, 15, 13, 7, 3, 11, 12],\n",
    "    \"Change_Coherent\": [14, 14, 3, 10, 3, 32, 0, 3, 10, 2, 4, 2, 1, 15],\n",
    "    \"Unchange_Count\": [83, 71, 90, 83, 71, 58, 82, 92, 73, 84, 89, 91, 84, 72],\n",
    "    \"Unchange_Incoherent\": [2, 0, 0, 5, 2, 0, 0, 1, 2, 0, 2, 6, 3, 1],\n",
    "    \"Unchange_Partially_Coherent\": [7, 0, 8, 16, 3, 3, 11, 30, 4, 17, 7, 10, 18, 3],\n",
    "    \"Unchange_Coherent\": [74, 71, 82, 62, 64, 55, 71, 61, 67, 67, 80, 75, 63, 68],\n",
    "}\n",
    "\n",
    "data_higher = {\n",
    "    \"Language\": [\n",
    "        \"en\",\n",
    "        \"de\",\n",
    "        \"fr\",\n",
    "        \"it\",\n",
    "        \"pt\",\n",
    "        \"hi\",\n",
    "        \"es\",\n",
    "        \"th\",\n",
    "        \"bg\",\n",
    "        \"ru\",\n",
    "        \"tr\",\n",
    "        \"vi\",\n",
    "        \"ja\",\n",
    "        \"ko\",\n",
    "        \"zh\",\n",
    "    ],\n",
    "    \"Alpha\": [\n",
    "        -1.2,\n",
    "        0.5,\n",
    "        0.4,\n",
    "        0.5,\n",
    "        0.25,\n",
    "        0.2,\n",
    "        0.8,\n",
    "        0.4,\n",
    "        0.5,\n",
    "        0.6,\n",
    "        0.3,\n",
    "        0.4,\n",
    "        0.4,\n",
    "        0.5,\n",
    "        0.4,\n",
    "    ],\n",
    "    \"Change_Count\": [5, 27, 38, 23, 12, 30, 45, 45, 22, 34, 27, 18, 19, 43, 66],\n",
    "    \"Change_Incoherent\": [1, 2, 14, 20, 3, 23, 1, 37, 12, 9, 11, 4, 8, 24, 7],\n",
    "    \"Change_Partially_Coherent\": [3, 13, 14, 3, 7, 5, 26, 8, 10, 12, 11, 9, 10, 18, 32],\n",
    "    \"Change_Coherent\": [1, 12, 10, 0, 2, 2, 18, 0, 0, 13, 5, 5, 1, 1, 27],\n",
    "    \"Unchange_Count\": [95, 73, 62, 77, 88, 70, 55, 55, 78, 66, 73, 82, 81, 57, 34],\n",
    "    \"Unchange_Incoherent\": [8, 3, 1, 2, 28, 9, 0, 2, 3, 15, 6, 11, 9, 6, 1],\n",
    "    \"Unchange_Partially_Coherent\": [10, 15, 0, 4, 17, 3, 1, 11, 32, 5, 8, 12, 10, 8, 2],\n",
    "    \"Unchange_Coherent\": [77, 55, 61, 71, 43, 58, 54, 41, 43, 46, 59, 59, 62, 43, 31],\n",
    "}\n",
    "\n",
    "ordered_languages = [\n",
    "    \"de\",\n",
    "    \"fr\",\n",
    "    \"it\",\n",
    "    \"pt\",\n",
    "    \"hi\",\n",
    "    \"es\",\n",
    "    \"th\",\n",
    "    \"bg\",\n",
    "    \"ru\",\n",
    "    \"tr\",\n",
    "    \"vi\",\n",
    "    \"ja\",\n",
    "    \"ko\",\n",
    "    \"zh\",\n",
    "]\n",
    "\n",
    "color_map = {\n",
    "    \"Coherent\": \"rgb(53, 167, 107)\",\n",
    "    \"Partially Coherent\": \"rgb(253, 174, 97)\",\n",
    "    \"Incoherent\": \"rgb(215, 48, 39)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df_lower = pd.DataFrame(data_lower)\n",
    "df_lower = df_lower.set_index(\"Language\").reindex(ordered_languages).reset_index()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_lower[\"Language\"],\n",
    "        y=df_lower[\"Change_Coherent\"],\n",
    "        name=\"Coherent\",\n",
    "        marker_color=color_map[\"Coherent\"],\n",
    "        text=df_lower[\"Change_Coherent\"],\n",
    "        textposition=\"inside\",\n",
    "        textfont=dict(color=\"white\", size=10),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_lower[\"Language\"],\n",
    "        y=df_lower[\"Change_Partially_Coherent\"],\n",
    "        name=\"Partially Coherent\",\n",
    "        marker_color=color_map[\"Partially Coherent\"],\n",
    "        text=df_lower[\"Change_Partially_Coherent\"],\n",
    "        textposition=\"inside\",\n",
    "        textfont=dict(color=\"white\", size=10),\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=df_lower[\"Language\"],\n",
    "        y=df_lower[\"Change_Incoherent\"],\n",
    "        name=\"Incoherent\",\n",
    "        marker_color=color_map[\"Incoherent\"],\n",
    "        text=df_lower[\"Change_Incoherent\"],\n",
    "        textposition=\"inside\",\n",
    "        textfont=dict(color=\"white\", size=10),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    barmode=\"stack\",\n",
    "    title=\"Changed Texts Count (Lower α)\",\n",
    "    xaxis_title=\"Language\",\n",
    "    yaxis_title=\"Count of Changed Texts\",\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=0.907,\n",
    "        xanchor=\"right\",\n",
    "        x=1,\n",
    "        traceorder=\"normal\",\n",
    "    ),\n",
    "    width=900,\n",
    "    height=500,\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig.write_image(\n",
    "    output_path / \"changed_texts_count.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both datasets\n",
    "df_lower = pd.DataFrame(data_lower)\n",
    "df_lower[\"Table\"] = \"Lower α\"\n",
    "\n",
    "df_higher = pd.DataFrame(data_higher)\n",
    "df_higher[\"Table\"] = \"Higher α\"\n",
    "\n",
    "# Remove English from higher as it's a special case with negative alpha\n",
    "df_higher_no_en = df_higher[df_higher[\"Language\"] != \"en\"].copy()\n",
    "\n",
    "# Combine dataframes\n",
    "df_combined = pd.concat([df_lower, df_higher_no_en])\n",
    "\n",
    "# Find languages that appear in both tables\n",
    "common_languages = set(df_lower[\"Language\"]).intersection(\n",
    "    set(df_higher_no_en[\"Language\"])\n",
    ")\n",
    "\n",
    "# Create a dataframe with paired data for languages that appear in both tables\n",
    "paired_data = []\n",
    "for lang in common_languages:\n",
    "    lower_row = df_lower[df_lower[\"Language\"] == lang].iloc[0]\n",
    "    higher_row = df_higher_no_en[df_higher_no_en[\"Language\"] == lang].iloc[0]\n",
    "\n",
    "    paired_data.append(\n",
    "        {\n",
    "            \"Language\": lang,\n",
    "            \"Alpha_Lower\": lower_row[\"Alpha\"],\n",
    "            \"Alpha_Higher\": higher_row[\"Alpha\"],\n",
    "            \"Change_Count_Lower\": lower_row[\"Change_Count\"],\n",
    "            \"Change_Count_Higher\": higher_row[\"Change_Count\"],\n",
    "            \"Change_Incoherent_Lower\": lower_row[\"Change_Incoherent\"],\n",
    "            \"Change_Incoherent_Higher\": higher_row[\"Change_Incoherent\"],\n",
    "            \"Change_Partially_Coherent_Lower\": lower_row[\"Change_Partially_Coherent\"],\n",
    "            \"Change_Partially_Coherent_Higher\": higher_row[\"Change_Partially_Coherent\"],\n",
    "            \"Change_Coherent_Lower\": lower_row[\"Change_Coherent\"],\n",
    "            \"Change_Coherent_Higher\": higher_row[\"Change_Coherent\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_paired = pd.DataFrame(paired_data)\n",
    "\n",
    "# Calculate percentages of coherence categories within the Changed texts\n",
    "df_paired[\"Change_Incoherent_Pct_Lower\"] = (\n",
    "    df_paired[\"Change_Incoherent_Lower\"] / df_paired[\"Change_Count_Lower\"] * 100\n",
    ")\n",
    "df_paired[\"Change_Partially_Coherent_Pct_Lower\"] = (\n",
    "    df_paired[\"Change_Partially_Coherent_Lower\"] / df_paired[\"Change_Count_Lower\"] * 100\n",
    ")\n",
    "df_paired[\"Change_Coherent_Pct_Lower\"] = (\n",
    "    df_paired[\"Change_Coherent_Lower\"] / df_paired[\"Change_Count_Lower\"] * 100\n",
    ")\n",
    "\n",
    "df_paired[\"Change_Incoherent_Pct_Higher\"] = (\n",
    "    df_paired[\"Change_Incoherent_Higher\"] / df_paired[\"Change_Count_Higher\"] * 100\n",
    ")\n",
    "df_paired[\"Change_Partially_Coherent_Pct_Higher\"] = (\n",
    "    df_paired[\"Change_Partially_Coherent_Higher\"]\n",
    "    / df_paired[\"Change_Count_Higher\"]\n",
    "    * 100\n",
    ")\n",
    "df_paired[\"Change_Coherent_Pct_Higher\"] = (\n",
    "    df_paired[\"Change_Coherent_Higher\"] / df_paired[\"Change_Count_Higher\"] * 100\n",
    ")\n",
    "\n",
    "# Sort by alpha difference to see the effect of increasing alpha\n",
    "df_paired[\"Alpha_Diff\"] = df_paired[\"Alpha_Higher\"] - df_paired[\"Alpha_Lower\"]\n",
    "df_paired = df_paired.sort_values(by=\"Alpha_Diff\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the paired dataframe according to the ordered language list\n",
    "df_paired[\"Language_Order\"] = df_paired[\"Language\"].apply(\n",
    "    lambda x: (\n",
    "        ordered_languages.index(x) if x in ordered_languages else len(ordered_languages)\n",
    "    )\n",
    ")\n",
    "df_paired = df_paired.sort_values(\"Language_Order\").reset_index(drop=True)\n",
    "\n",
    "# Figure 1: Comparing change in language generation at different alpha values\n",
    "fig1 = go.Figure()\n",
    "\n",
    "# Add lines for each coherence category\n",
    "fig1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_paired[\"Language\"],\n",
    "        y=df_paired[\"Change_Count_Lower\"],\n",
    "        mode=\"markers+lines\",\n",
    "        name=\"Changed Text Count (Lower α)\",\n",
    "        marker=dict(size=10, color=\"blue\"),\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig1.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_paired[\"Language\"],\n",
    "        y=df_paired[\"Change_Count_Higher\"],\n",
    "        mode=\"markers+lines\",\n",
    "        name=\"Changed Text Count (Higher α)\",\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        line=dict(width=2),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add alpha values as annotations\n",
    "for i, row in df_paired.iterrows():\n",
    "    fig1.add_annotation(\n",
    "        x=row[\"Language\"],\n",
    "        y=row[\"Change_Count_Lower\"],\n",
    "        text=f\"α={row['Alpha_Lower']}\",\n",
    "        showarrow=False,\n",
    "        yshift=-20,\n",
    "        font=dict(size=10, color=\"blue\"),\n",
    "    )\n",
    "    fig1.add_annotation(\n",
    "        x=row[\"Language\"],\n",
    "        y=row[\"Change_Count_Higher\"],\n",
    "        text=f\"α={row['Alpha_Higher']}\",\n",
    "        showarrow=False,\n",
    "        yshift=10,\n",
    "        font=dict(size=10, color=\"red\"),\n",
    "    )\n",
    "\n",
    "fig1.update_layout(\n",
    "    title=\"Impact of Increasing Scaling Factor (α) on Language Generation\",\n",
    "    xaxis_title=\"Target Language\",\n",
    "    yaxis_title=\"Count of Texts Changed to Target Language\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    hovermode=\"x unified\",\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "fig1.update_xaxes(\n",
    "    categoryorder=\"array\",\n",
    "    categoryarray=ordered_languages,\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "fig1.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks=\"outside\",\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    gridcolor=\"lightgrey\",\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig1.write_image(\n",
    "    output_path / \"impact_of_increasing_scaling_factor_on_language_generation.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Coherence breakdown as stacked bars\n",
    "fig2 = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Lower α Values\", \"Higher α Values\"),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
    ")\n",
    "\n",
    "# Convert dataframe to long format for easier plotting\n",
    "coherence_data = []\n",
    "\n",
    "for i, row in df_paired.iterrows():\n",
    "    # Lower alpha values\n",
    "    coherence_data.append(\n",
    "        {\n",
    "            \"Language\": row[\"Language\"],\n",
    "            \"Alpha Value\": \"Lower\",\n",
    "            \"Alpha\": row[\"Alpha_Lower\"],\n",
    "            \"Category\": \"Coherent\",\n",
    "            \"Percentage\": row[\"Change_Coherent_Pct_Lower\"],\n",
    "        }\n",
    "    )\n",
    "    coherence_data.append(\n",
    "        {\n",
    "            \"Language\": row[\"Language\"],\n",
    "            \"Alpha Value\": \"Lower\",\n",
    "            \"Alpha\": row[\"Alpha_Lower\"],\n",
    "            \"Category\": \"Partially Coherent\",\n",
    "            \"Percentage\": row[\"Change_Partially_Coherent_Pct_Lower\"],\n",
    "        }\n",
    "    )\n",
    "    coherence_data.append(\n",
    "        {\n",
    "            \"Language\": row[\"Language\"],\n",
    "            \"Alpha Value\": \"Lower\",\n",
    "            \"Alpha\": row[\"Alpha_Lower\"],\n",
    "            \"Category\": \"Incoherent\",\n",
    "            \"Percentage\": row[\"Change_Incoherent_Pct_Lower\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Higher alpha values\n",
    "    coherence_data.append(\n",
    "        {\n",
    "            \"Language\": row[\"Language\"],\n",
    "            \"Alpha Value\": \"Higher\",\n",
    "            \"Alpha\": row[\"Alpha_Higher\"],\n",
    "            \"Category\": \"Coherent\",\n",
    "            \"Percentage\": row[\"Change_Coherent_Pct_Higher\"],\n",
    "        }\n",
    "    )\n",
    "    coherence_data.append(\n",
    "        {\n",
    "            \"Language\": row[\"Language\"],\n",
    "            \"Alpha Value\": \"Higher\",\n",
    "            \"Alpha\": row[\"Alpha_Higher\"],\n",
    "            \"Category\": \"Partially Coherent\",\n",
    "            \"Percentage\": row[\"Change_Partially_Coherent_Pct_Higher\"],\n",
    "        }\n",
    "    )\n",
    "    coherence_data.append(\n",
    "        {\n",
    "            \"Language\": row[\"Language\"],\n",
    "            \"Alpha Value\": \"Higher\",\n",
    "            \"Alpha\": row[\"Alpha_Higher\"],\n",
    "            \"Category\": \"Incoherent\",\n",
    "            \"Percentage\": row[\"Change_Incoherent_Pct_Higher\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_coherence = pd.DataFrame(coherence_data)\n",
    "\n",
    "# Plot lower alpha coherence breakdown\n",
    "for category in [\"Coherent\", \"Partially Coherent\", \"Incoherent\"]:\n",
    "    df_cat = df_coherence[\n",
    "        (df_coherence[\"Alpha Value\"] == \"Lower\")\n",
    "        & (df_coherence[\"Category\"] == category)\n",
    "    ]\n",
    "\n",
    "    # Reorder data according to language_order\n",
    "    df_cat = df_cat.set_index(\"Language\").reindex(ordered_languages).reset_index()\n",
    "\n",
    "    fig2.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cat[\"Language\"],\n",
    "            y=df_cat[\"Percentage\"],\n",
    "            name=category,\n",
    "            marker_color=color_map[category],\n",
    "            legendgroup=category,\n",
    "            showlegend=True,\n",
    "            text=[f\"{val:.1f}%\" for val in df_cat[\"Percentage\"]],\n",
    "            textposition=\"inside\",\n",
    "            textfont=dict(color=\"white\", size=10),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Plot higher alpha coherence breakdown\n",
    "for category in [\"Coherent\", \"Partially Coherent\", \"Incoherent\"]:\n",
    "    df_cat = df_coherence[\n",
    "        (df_coherence[\"Alpha Value\"] == \"Higher\")\n",
    "        & (df_coherence[\"Category\"] == category)\n",
    "    ]\n",
    "\n",
    "    # Reorder data according to language_order\n",
    "    df_cat = df_cat.set_index(\"Language\").reindex(ordered_languages).reset_index()\n",
    "\n",
    "    fig2.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_cat[\"Language\"],\n",
    "            y=df_cat[\"Percentage\"],\n",
    "            name=category,\n",
    "            marker_color=color_map[category],\n",
    "            legendgroup=category,\n",
    "            showlegend=False,\n",
    "            text=[f\"{val:.1f}%\" for val in df_cat[\"Percentage\"]],\n",
    "            textposition=\"inside\",\n",
    "            textfont=dict(color=\"white\", size=10),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "\n",
    "# Add alpha values as annotations on x-axis\n",
    "for col, alpha_val in enumerate([\"Lower\", \"Higher\"], 1):\n",
    "    for i, lang in enumerate(ordered_languages):\n",
    "        alpha = df_paired[df_paired[\"Language\"] == lang][f\"Alpha_{alpha_val}\"].values[0]\n",
    "        fig2.add_annotation(\n",
    "            x=lang,\n",
    "            y=-10,\n",
    "            text=f\"α={alpha}\",\n",
    "            showarrow=False,\n",
    "            xref=f\"x{col}\",\n",
    "            yref=f\"y{col}\",\n",
    "            font=dict(size=10),\n",
    "        )\n",
    "\n",
    "fig2.update_layout(\n",
    "    title=\"Impact of Scaling Factor (α) on Text Coherence in Changed Languages\",\n",
    "    barmode=\"stack\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.115, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    yaxis2=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    xaxis=dict(title=\"Target Language\"),\n",
    "    xaxis2=dict(title=\"Target Language\"),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig2.write_image(\n",
    "    output_path / \"impact_of_scaling_factor_on_text_coherence_changed.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2b = make_subplots(\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    subplot_titles=(\"Lower α Values\", \"Higher α Values\"),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]],\n",
    ")\n",
    "\n",
    "unchanged_coherence_data = []\n",
    "for _, row in df_paired.iterrows():\n",
    "    lang = row[\"Language\"]\n",
    "    lower = df_lower.loc[df_lower[\"Language\"] == lang].iloc[0]\n",
    "    higher = df_higher_no_en.loc[df_higher_no_en[\"Language\"] == lang].iloc[0]\n",
    "\n",
    "    # Lower α\n",
    "    total_lower = (\n",
    "        lower[\"Unchange_Coherent\"]\n",
    "        + lower[\"Unchange_Partially_Coherent\"]\n",
    "        + lower[\"Unchange_Incoherent\"]\n",
    "    )\n",
    "    if total_lower > 0:\n",
    "        unchanged_coherence_data += [\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Coherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Coherent\"] / total_lower * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Partially Coherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Partially_Coherent\"] / total_lower * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Lower\",\n",
    "                \"Category\": \"Incoherent\",\n",
    "                \"Percentage\": lower[\"Unchange_Incoherent\"] / total_lower * 100,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    # Higher α\n",
    "    total_higher = (\n",
    "        higher[\"Unchange_Coherent\"]\n",
    "        + higher[\"Unchange_Partially_Coherent\"]\n",
    "        + higher[\"Unchange_Incoherent\"]\n",
    "    )\n",
    "    if total_higher > 0:\n",
    "        unchanged_coherence_data += [\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Coherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Coherent\"] / total_higher * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Partially Coherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Partially_Coherent\"]\n",
    "                / total_higher\n",
    "                * 100,\n",
    "            },\n",
    "            {\n",
    "                \"Language\": lang,\n",
    "                \"Alpha Value\": \"Higher\",\n",
    "                \"Category\": \"Incoherent\",\n",
    "                \"Percentage\": higher[\"Unchange_Incoherent\"] / total_higher * 100,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "df_unchanged_coherence = pd.DataFrame(unchanged_coherence_data)\n",
    "\n",
    "language_order = df_paired[\"Language\"].tolist()\n",
    "\n",
    "for col, alpha_val in enumerate([\"Lower\", \"Higher\"], start=1):\n",
    "    for category in [\"Coherent\", \"Partially Coherent\", \"Incoherent\"]:\n",
    "        df_cat = (\n",
    "            df_unchanged_coherence.query(\n",
    "                \"`Alpha Value` == @alpha_val and Category == @category\"\n",
    "            )\n",
    "            .set_index(\"Language\")\n",
    "            .reindex(language_order)\n",
    "            .reset_index()\n",
    "        )\n",
    "        fig2b.add_trace(\n",
    "            go.Bar(\n",
    "                x=df_cat[\"Language\"],\n",
    "                y=df_cat[\"Percentage\"],\n",
    "                name=category,\n",
    "                marker_color=color_map[category],\n",
    "                legendgroup=category,\n",
    "                showlegend=(col == 1),\n",
    "                text=[f\"{v:.1f}%\" for v in df_cat[\"Percentage\"]],\n",
    "                textposition=\"inside\",\n",
    "                textfont=dict(color=\"white\", size=10),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "    for lang in language_order:\n",
    "        α = (\n",
    "            row[f\"Alpha_{alpha_val}\"]\n",
    "            if False\n",
    "            else df_paired.loc[\n",
    "                df_paired[\"Language\"] == lang, f\"Alpha_{alpha_val}\"\n",
    "            ].iloc[0]\n",
    "        )\n",
    "        fig2b.add_annotation(\n",
    "            x=lang,\n",
    "            y=-5,\n",
    "            text=f\"α={α}\",\n",
    "            showarrow=False,\n",
    "            xref=f\"x{col}\",\n",
    "            yref=f\"y{col}\",\n",
    "            font=dict(size=10),\n",
    "        )\n",
    "\n",
    "fig2b.update_layout(\n",
    "    title=\"Impact of Scaling Factor (α) on Text Coherence in Unchanged Languages\",\n",
    "    barmode=\"stack\",\n",
    "    legend=dict(orientation=\"h\", yanchor=\"top\", y=1.115, xanchor=\"right\", x=1),\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    yaxis2=dict(title=\"Percentage (%)\", range=[0, 100]),\n",
    "    xaxis=dict(title=\"Target Language\"),\n",
    "    xaxis2=dict(title=\"Target Language\"),\n",
    "    plot_bgcolor=\"white\",\n",
    ")\n",
    "\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"images\"\n",
    "    / \"visualization\"\n",
    "    / \"text_generation\"\n",
    "    / \"meta-llama\"\n",
    "    / \"Llama-3.2-1B\"\n",
    "    / \"EleutherAI\"\n",
    "    / \"sae-Llama-3.2-1B-131k\"\n",
    "    / \"all\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "fig2b.write_image(\n",
    "    output_path / \"impact_of_scaling_factor_on_text_coherence_unchanged.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language-specific features Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation_folder = project_dir / \"interpret_sae_features\" / \"explanations\"\n",
    "scores_path = project_dir / \"interpret_sae_features\" / \"scores\"\n",
    "\n",
    "visualize_path = project_dir / \"visualization\" / \"interpret_sae_features\" / \"scores\"\n",
    "\n",
    "hookpoints = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]\n",
    "\n",
    "interpretations = load_all_interpretations(interpretation_folder)\n",
    "latent_df, counts = load_data(scores_path, hookpoints)\n",
    "df_metrics = get_metrics_per_latent(latent_df)\n",
    "metrics = convert_df_metrics_to_nested_dict(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result_path = (\n",
    "    project_dir\n",
    "    / \"sae_features_specific\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"lape_all.pt\"\n",
    ")\n",
    "\n",
    "lape_all_result = torch.load(lape_all_result_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_score_result(lape_result, df_metrics):\n",
    "    score_results = {}\n",
    "\n",
    "    sorted_lang = lape_result[\"sorted_lang\"]\n",
    "\n",
    "    for lang_idx, lang in enumerate(sorted_lang):\n",
    "        lang_final_indices = lape_result[\"final_indice\"][lang_idx]\n",
    "\n",
    "        combined_df = None\n",
    "\n",
    "        for layer_idx, _ in enumerate(lang_final_indices):\n",
    "            lang_layer_final_indices = lang_final_indices[layer_idx].tolist()\n",
    "            layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "\n",
    "            combined_df = pd.concat(\n",
    "                [\n",
    "                    combined_df,\n",
    "                    df_metrics.query(\n",
    "                        \"layer == @layer_str and latent_idx in @lang_layer_final_indices\"\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        score_results[lang] = (\n",
    "            combined_df.groupby(\"score_type\")[[\"accuracy\", \"f1_score\", \"precision\", \"recall\",]]\n",
    "            .mean()\n",
    "            .to_dict(orient=\"index\")\n",
    "        )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for lang, score_types in score_results.items():\n",
    "        for score_type, metrics in score_types.items():\n",
    "            row = {\"Language\": lang, \"Score Type\": score_type}\n",
    "            row.update(metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    df_scores[[\"accuracy\", \"f1_score\", \"precision\", \"recall\"]] = df_scores[\n",
    "        [\"accuracy\", \"f1_score\", \"precision\", \"recall\",]\n",
    "    ].round(2)\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score_result = get_mean_score_result(lape_all_result, df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro average\n",
    "macro_averages = average_score_result.groupby(\"Score Type\")[[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]].mean().round(2)\n",
    "macro_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check average scores\n",
    "macro_averages.reset_index()[\n",
    "    [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "].mean().round(\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Micro average\n",
    "df_metrics.groupby(\"score_type\")[[\"accuracy\", \"f1_score\", \"precision\", \"recall\"]].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_dir / \"interpret_sae_features\" / \"scores\" / \"average_scores.csv\"\n",
    "average_score_result.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_score_result(lape_result, df_metrics):\n",
    "    score_results = {}\n",
    "\n",
    "    sorted_lang = lape_result[\"sorted_lang\"]\n",
    "\n",
    "    for lang_idx, lang in enumerate(sorted_lang):\n",
    "        lang_final_indices = lape_result[\"final_indice\"][lang_idx]\n",
    "\n",
    "        combined_df = None\n",
    "\n",
    "        for layer_idx, _ in enumerate(lang_final_indices):\n",
    "            lang_layer_final_indices = lang_final_indices[layer_idx].tolist()\n",
    "            layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "\n",
    "            combined_df = pd.concat(\n",
    "                [\n",
    "                    combined_df,\n",
    "                    df_metrics.query(\n",
    "                        \"layer == @layer_str and latent_idx in @lang_layer_final_indices\"\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        score_results[lang] = (\n",
    "            combined_df.groupby(\"score_type\")[\n",
    "                [\n",
    "                    \"accuracy\",\n",
    "                    \"f1_score\",\n",
    "                    \"precision\",\n",
    "                    \"recall\",\n",
    "                ]\n",
    "            ]\n",
    "            .agg(\n",
    "                [\n",
    "                    (\"q1\", lambda x: x.quantile(0.25)),\n",
    "                    (\"median\", \"median\"),\n",
    "                    (\"q3\", lambda x: x.quantile(0.75)),\n",
    "                ]\n",
    "            )\n",
    "            .to_dict(orient=\"index\")\n",
    "        )\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for lang, score_types in score_results.items():\n",
    "        for score_type, metrics in score_types.items():\n",
    "            row = {\"Language\": lang, \"Score Type\": score_type}\n",
    "            row.update(metrics)\n",
    "            rows.append(row)\n",
    "\n",
    "    df_scores = pd.DataFrame(rows)\n",
    "    df_scores.columns = [\n",
    "        f\"{col[0]}_{col[1]}\" if isinstance(col, tuple) else col for col in df_scores.columns\n",
    "    ]\n",
    "    metric_cols = [\n",
    "        \"accuracy_q1\", \"accuracy_median\", \"accuracy_q3\",\n",
    "        \"f1_score_q1\", \"f1_score_median\", \"f1_score_q3\",\n",
    "        \"precision_q1\", \"precision_median\", \"precision_q3\",\n",
    "        \"recall_q1\", \"recall_median\", \"recall_q3\",\n",
    "    ]\n",
    "    df_scores[metric_cols] = df_scores[metric_cols].round(2)\n",
    "\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_score_result = get_median_score_result(lape_all_result, df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_score_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro average\n",
    "metric_cols = [\n",
    "    \"accuracy_q1\",\n",
    "    \"accuracy_median\",\n",
    "    \"accuracy_q3\",\n",
    "    \"f1_score_q1\",\n",
    "    \"f1_score_median\",\n",
    "    \"f1_score_q3\",\n",
    "    \"precision_q1\",\n",
    "    \"precision_median\",\n",
    "    \"precision_q3\",\n",
    "    \"recall_q1\",\n",
    "    \"recall_median\",\n",
    "    \"recall_q3\",\n",
    "]\n",
    "\n",
    "macro_averages = median_score_result.groupby(\"Score Type\")[metric_cols].mean().round(2)\n",
    "macro_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median of median\n",
    "macro_averages = median_score_result.groupby(\"Score Type\")[metric_cols].median().round(2)\n",
    "macro_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Median\n",
    "df_metrics.groupby(\"score_type\")[[\"accuracy\", \"f1_score\", \"precision\", \"recall\"]].agg(\n",
    "    [\n",
    "        (\"q1\", lambda x: x.quantile(0.25)),\n",
    "        (\"median\", \"median\"),\n",
    "        (\"q3\", lambda x: x.quantile(0.75)),\n",
    "    ]\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features similarity (IoU and Pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lape_all_result[\"sorted_lang\"].index(\"Hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"similarity\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    ")\n",
    "\n",
    "task_configs = {\n",
    "    \"xnli\": {\n",
    "        \"path\": data_path_dataset_token_activations_xnli,\n",
    "        \"config\": config_xnli,\n",
    "    },\n",
    "    \"paws-x\": {\n",
    "        \"path\": data_path_dataset_token_activations_pawsx,\n",
    "        \"config\": config_pawsx,\n",
    "    },\n",
    "    \"flores\": {\n",
    "        \"path\": data_path_dataset_token_activations_flores,\n",
    "        \"config\": config_flores,\n",
    "    },\n",
    "}\n",
    "\n",
    "plot_features_similarity(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    output_dir,\n",
    "    task_configs,\n",
    "    start_index=5,\n",
    "    end_index=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Similarity of Language-Specific Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "lang_to_sae_features = {\n",
    "    lang: {\n",
    "        \"final_indices\": [],\n",
    "        \"stacked_sae_features\": [],\n",
    "    }\n",
    "    for lang in sorted_lang\n",
    "}\n",
    "\n",
    "\n",
    "for lang_idx, lang in enumerate(sorted_lang):\n",
    "    lang_final_indices = lape_all_result[\"final_indice\"][lang_idx]\n",
    "    lang_sae_features = lape_all_result[\"sae_features\"][lang_idx]\n",
    "\n",
    "    lang_to_sae_features[lang][\"final_indices\"] = [\n",
    "        indices.tolist() for indices in lang_final_indices\n",
    "    ]\n",
    "    lang_to_sae_features[lang][\"stacked_sae_features\"] = [\n",
    "        features.tolist() for features in lang_sae_features\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Collect all features and create language boundaries\n",
    "all_features = []\n",
    "all_feature_indices = []\n",
    "all_layer_numbers = []\n",
    "language_boundaries = []\n",
    "current_position = 0\n",
    "lang_names_for_features = []\n",
    "\n",
    "# Stack all features from all languages\n",
    "for lang in sorted_lang:\n",
    "    lang_features = lang_to_sae_features[lang][\"stacked_sae_features\"]\n",
    "    lang_indices = lang_to_sae_features[lang][\"final_indices\"]\n",
    "\n",
    "    # Each element in stacked_sae_features corresponds to a layer/position\n",
    "    # and contains feature vectors for the indices found at that position\n",
    "    for layer_idx, feature_vectors in enumerate(lang_features):\n",
    "        layer_indices = lang_indices[\n",
    "            layer_idx\n",
    "        ]  # Get corresponding indices for this layer\n",
    "\n",
    "        # feature_vectors is a list of feature vectors for this layer\n",
    "        for feat_idx, feature_vector in enumerate(feature_vectors):\n",
    "            all_features.append(feature_vector)\n",
    "            # Get the actual feature index from final_indices\n",
    "            if feat_idx < len(layer_indices):\n",
    "                actual_index = layer_indices[feat_idx]\n",
    "            else:\n",
    "                actual_index = f\"unknown_{current_position}\"\n",
    "            all_feature_indices.append(actual_index)\n",
    "            all_layer_numbers.append(layer_idx)  # Store the layer number\n",
    "            lang_names_for_features.append(lang)\n",
    "            current_position += 1\n",
    "\n",
    "    # Mark the boundary after this language\n",
    "    language_boundaries.append(current_position)\n",
    "\n",
    "# Convert to numpy array for cosine similarity calculation\n",
    "features_array = np.array(all_features)\n",
    "print(f\"Feature array shape: {features_array.shape}\")\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(features_array)\n",
    "\n",
    "# Create the heatmap\n",
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=similarity_matrix,\n",
    "        colorscale=\"RdBu\",\n",
    "        zmid=0,  # Center the colorscale at 0\n",
    "        colorbar=dict(\n",
    "            title=\"Cosine Similarity\",\n",
    "        ),\n",
    "        hovertemplate=\"Lang: %{customdata[0]}<br>Layer: %{customdata[1]}, Index: %{customdata[2]}<br>Lang: %{customdata[3]}<br>Layer: %{customdata[4]}, Index: %{customdata[5]}<br>Similarity: %{z:.3f}<extra></extra>\",\n",
    "        customdata=np.array(\n",
    "            [\n",
    "                [\n",
    "                    lang_names_for_features[i],\n",
    "                    all_layer_numbers[i],\n",
    "                    all_feature_indices[i],\n",
    "                    lang_names_for_features[j],\n",
    "                    all_layer_numbers[j],\n",
    "                    all_feature_indices[j],\n",
    "                ]\n",
    "                for i in range(len(all_feature_indices))\n",
    "                for j in range(len(all_feature_indices))\n",
    "            ]\n",
    "        ).reshape(len(all_feature_indices), len(all_feature_indices), 6),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add language boundaries as lines\n",
    "boundary_color = \"black\"\n",
    "boundary_width = 2\n",
    "\n",
    "# Add vertical lines for language boundaries\n",
    "for boundary in language_boundaries[:-1]:  # Exclude the last boundary (end of data)\n",
    "    fig.add_vline(\n",
    "        x=boundary - 0.5,\n",
    "        line=dict(color=boundary_color, width=boundary_width),\n",
    "        layer=\"above\",\n",
    "    )\n",
    "\n",
    "# Add horizontal lines for language boundaries\n",
    "for boundary in language_boundaries[:-1]:\n",
    "    fig.add_hline(\n",
    "        y=boundary - 0.5,\n",
    "        line=dict(color=boundary_color, width=boundary_width),\n",
    "        layer=\"above\",\n",
    "    )\n",
    "\n",
    "# Create language labels for the plot\n",
    "lang_positions = []\n",
    "lang_labels = []\n",
    "prev_boundary = 0\n",
    "\n",
    "for i, (lang, boundary) in enumerate(zip(sorted_lang, language_boundaries)):\n",
    "    # Calculate the middle position for each language section\n",
    "    middle_pos = (prev_boundary + boundary) / 2\n",
    "    lang_positions.append(middle_pos)\n",
    "    lang_labels.append(lang)\n",
    "    prev_boundary = boundary\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Cosine Similarity Heatmap of Language-Specific Features\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"font\": {\"size\": 16},\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title=\"Feature Index\",\n",
    "        tickfont=dict(size=6),\n",
    "        # Add language labels at appropriate positions\n",
    "        tickmode=\"array\",\n",
    "        tickvals=lang_positions,\n",
    "        ticktext=lang_labels,\n",
    "        tickangle=45,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Feature Index\",\n",
    "        tickfont=dict(size=6),\n",
    "        # Add language labels at appropriate positions\n",
    "        tickmode=\"array\",\n",
    "        tickvals=lang_positions,\n",
    "        ticktext=lang_labels,\n",
    "        autorange=\"reversed\",  # Reverse y-axis to match typical matrix visualization\n",
    "    ),\n",
    "    # width=800,\n",
    "    height=1000,\n",
    "    font=dict(size=10),\n",
    ")\n",
    "\n",
    "# Add annotations for language boundaries\n",
    "annotations = []\n",
    "for i, lang in enumerate(sorted_lang):\n",
    "    # Add language labels on the diagonal\n",
    "    pos = lang_positions[i]\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x=pos,\n",
    "            y=pos,\n",
    "            text=lang,\n",
    "            showarrow=False,\n",
    "            font=dict(color=\"white\", size=8, family=\"Arial Black\"),\n",
    "            bgcolor=\"rgba(0,0,0,0.7)\",\n",
    "            bordercolor=\"white\",\n",
    "            borderwidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(annotations=annotations)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"\\nSimilarity Matrix Statistics:\")\n",
    "print(f\"Shape: {similarity_matrix.shape}\")\n",
    "print(f\"Min similarity: {similarity_matrix.min():.3f}\")\n",
    "print(f\"Max similarity: {similarity_matrix.max():.3f}\")\n",
    "print(f\"Mean similarity: {similarity_matrix.mean():.3f}\")\n",
    "\n",
    "# Print language boundaries for reference\n",
    "print(f\"\\nLanguage boundaries:\")\n",
    "for i, (lang, boundary) in enumerate(zip(sorted_lang, language_boundaries)):\n",
    "    start = language_boundaries[i - 1] if i > 0 else 0\n",
    "    feature_count = boundary - start\n",
    "    print(f\"{lang}: features {start} to {boundary-1} (total: {feature_count} features)\")\n",
    "\n",
    "    # Show some example feature indices and layers for this language\n",
    "    lang_feature_indices = all_feature_indices[start:boundary]\n",
    "    lang_layer_numbers = all_layer_numbers[start:boundary]\n",
    "    examples = [\n",
    "        (layer, idx)\n",
    "        for layer, idx in zip(lang_layer_numbers[:5], lang_feature_indices[:5])\n",
    "    ]\n",
    "    print(f\"  Example (layer, index): {examples}{'...' if feature_count > 5 else ''}\")\n",
    "\n",
    "# Print total feature count\n",
    "print(f\"\\nTotal features collected: {len(all_features)}\")\n",
    "print(f\"Languages: {len(sorted_lang)}\")\n",
    "print(\n",
    "    f\"Feature indices range: {min(all_feature_indices)} to {max(all_feature_indices)}\"\n",
    ")\n",
    "print(f\"Layer numbers range: {min(all_layer_numbers)} to {max(all_layer_numbers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsify import Sae\n",
    "\n",
    "sae_vectors = {}\n",
    "\n",
    "layers = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]\n",
    "\n",
    "for layer in layers:\n",
    "    sae = Sae.load_from_hub(\"EleutherAI/sae-Llama-3.2-1B-131k\", hookpoint=layer)\n",
    "\n",
    "    sae_vectors[layer] = {\n",
    "        \"bias\": sae.b_dec.detach(),\n",
    "    }\n",
    "\n",
    "    del sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    \"Language\": [],\n",
    "    \"Layer\": [],\n",
    "    \"Index\": [],\n",
    "    \"Similarity\": [],\n",
    "}\n",
    "\n",
    "for lang, layer_final_indices in lang_to_sae_features.items():\n",
    "    for layer_idx, final_indices in enumerate(layer_final_indices[\"final_indices\"]):\n",
    "        layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "        bias_vector = sae_vectors[layer_str][\"bias\"]\n",
    "\n",
    "        # Get the feature vectors for this language and layer\n",
    "        feature_vectors = layer_final_indices[\"stacked_sae_features\"][layer_idx]\n",
    "        lang_layer_feature_indices = layer_final_indices[\"final_indices\"][layer_idx]\n",
    "\n",
    "        if len(feature_vectors) == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate cosine similarity between bias vector and feature vectors\n",
    "        similarity_scores = cosine_similarity(bias_vector.unsqueeze(0), feature_vectors)\n",
    "\n",
    "        for idx, score in zip(lang_layer_feature_indices, similarity_scores[0]):\n",
    "            records[\"Language\"].append(lang)\n",
    "            records[\"Layer\"].append(layer_str)\n",
    "            records[\"Index\"].append(idx)\n",
    "            records[\"Similarity\"].append(score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_dir / \"hfls\" / \"sae_bias_similarity.csv\"\n",
    "\n",
    "pd.DataFrame(records).to_csv(output_path, index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cosine Similarity of Language-Specific Features in particular layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsify import Sae\n",
    "\n",
    "sae_vectors = {}\n",
    "\n",
    "layers = [\n",
    "    \"layers.0.mlp\",\n",
    "    \"layers.1.mlp\",\n",
    "    \"layers.2.mlp\",\n",
    "    \"layers.3.mlp\",\n",
    "    \"layers.4.mlp\",\n",
    "    \"layers.5.mlp\",\n",
    "    \"layers.6.mlp\",\n",
    "    \"layers.7.mlp\",\n",
    "    \"layers.8.mlp\",\n",
    "    \"layers.9.mlp\",\n",
    "    \"layers.10.mlp\",\n",
    "    \"layers.11.mlp\",\n",
    "    \"layers.12.mlp\",\n",
    "    \"layers.13.mlp\",\n",
    "    \"layers.14.mlp\",\n",
    "    \"layers.15.mlp\",\n",
    "]\n",
    "\n",
    "sorted_lang = lape_all_result[\"sorted_lang\"]\n",
    "\n",
    "records = {\n",
    "    \"Language\": [],\n",
    "    \"Layer\": [],\n",
    "    \"Feature Index\": [],\n",
    "    \"Opposing Feature Index\": [],\n",
    "    \"Cosine Similarity\": [],\n",
    "}\n",
    "\n",
    "for layer in layers:\n",
    "    print(f\"Processing layer: {layer}\")\n",
    "\n",
    "    sae = Sae.load_from_hub(\"EleutherAI/sae-Llama-3.2-1B-131k\", hookpoint=layer)\n",
    "    layer_idx = hookpoint_to_layer[layer]\n",
    "\n",
    "    for lang_index, lang in enumerate(sorted_lang):\n",
    "        lang_layer_sae_features = lape_all_result[\"sae_features\"][lang_index][layer_idx]\n",
    "        lang_layer_sae_feature_indices = lape_all_result[\"final_indice\"][lang_index][\n",
    "            layer_idx\n",
    "        ]\n",
    "\n",
    "        if len(lang_layer_sae_features) == 0:\n",
    "            continue\n",
    "\n",
    "        similarity_matrix = cosine_similarity(\n",
    "            lang_layer_sae_features, sae.W_dec.detach()\n",
    "        )\n",
    "\n",
    "        opposing_vectors = similarity_matrix.argmin(axis=-1)\n",
    "        opposing_values = similarity_matrix.min(axis=-1)\n",
    "\n",
    "        for feature, opposing_vector, opposing_value in zip(\n",
    "            lang_layer_sae_feature_indices, opposing_vectors, opposing_values\n",
    "        ):\n",
    "            records[\"Language\"].append(lang)\n",
    "            records[\"Layer\"].append(layer)\n",
    "            records[\"Feature Index\"].append(feature.item())\n",
    "            records[\"Opposing Feature Index\"].append(opposing_vector.item())\n",
    "            records[\"Cosine Similarity\"].append(opposing_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_dir / \"hfls\" / \"sae_opposing_features.csv\"\n",
    "\n",
    "os.makedirs(output_path.parent, exist_ok=True)\n",
    "\n",
    "pd.DataFrame(records).to_csv(output_path, index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_dataset_token_activations_xnli = (\n",
    "    statistic_dir\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / config_xnli[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_pawsx = (\n",
    "    statistic_dir\n",
    "    / config_pawsx[\"model\"]\n",
    "    / config_pawsx[\"sae\"][\"model\"]\n",
    "    / config_pawsx[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")\n",
    "\n",
    "data_path_dataset_token_activations_flores = (\n",
    "    statistic_dir\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"dataset_token_activations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_count_and_intersection(\n",
    "    feature_indices: tuple[int, int],\n",
    "    layer: str,\n",
    "):\n",
    "    feature_token_count = 0\n",
    "    opposing_feature_token_count = 0\n",
    "    intersection_count = 0\n",
    "\n",
    "    for config, data_path in [\n",
    "        (config_xnli, data_path_dataset_token_activations_xnli),\n",
    "        (config_pawsx, data_path_dataset_token_activations_pawsx),\n",
    "        (config_flores, data_path_dataset_token_activations_flores),\n",
    "    ]:\n",
    "        lang_to_dataset_token_activations_xnli = load_lang_to_dataset_token_activations(\n",
    "            data_path,\n",
    "            layer,\n",
    "            config[\"languages\"],\n",
    "            feature_indices,\n",
    "        )\n",
    "\n",
    "        for (\n",
    "            _,\n",
    "            lang_to_dataset_token_activations,\n",
    "        ) in lang_to_dataset_token_activations_xnli.items():\n",
    "            feature = lang_to_dataset_token_activations.query(\n",
    "                \"index == @feature_indices[0]\"\n",
    "            )\n",
    "            opposing_feature = lang_to_dataset_token_activations.query(\n",
    "                \"index == @feature_indices[1]\"\n",
    "            )\n",
    "\n",
    "            if not feature.empty:\n",
    "                feature_token_count += feature[\"count\"].item()\n",
    "\n",
    "            if not opposing_feature.empty:\n",
    "                opposing_feature_token_count += opposing_feature[\"count\"].item()\n",
    "\n",
    "            if not feature.empty and not opposing_feature.empty:\n",
    "                feature_dataset_row_id_token_id = {\n",
    "                    (row_id, token_id)\n",
    "                    for row_id, token_id, _ in literal_eval(\n",
    "                        feature[\"dataset_row_id_token_id_act_val\"].item()\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                opposing_feature_dataset_row_id_token_id = {\n",
    "                    (row_id, token_id)\n",
    "                    for row_id, token_id, _ in literal_eval(\n",
    "                        opposing_feature[\"dataset_row_id_token_id_act_val\"].item()\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                intersection_count += len(\n",
    "                    feature_dataset_row_id_token_id\n",
    "                    & opposing_feature_dataset_row_id_token_id\n",
    "                )\n",
    "\n",
    "    return (feature_token_count, opposing_feature_token_count, intersection_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_dir / \"hfls\" / \"sae_opposing_features.csv\"\n",
    "\n",
    "records = pd.read_csv(\n",
    "    output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records[\n",
    "    [\"Feature Token Count\", \"Opposing Feature Token Count\", \"Intersection Count\"]\n",
    "] = records[[\"Feature Index\", \"Opposing Feature Index\", \"Layer\"]].apply(\n",
    "    lambda row: feature_count_and_intersection(\n",
    "        (row[\"Feature Index\"], row[\"Opposing Feature Index\"]),\n",
    "        f\"model.{row['Layer']}\",\n",
    "    ),\n",
    "    axis=1,\n",
    "    result_type=\"expand\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = project_dir / \"hfls\" / \"sae_opposing_features.csv\"\n",
    "\n",
    "os.makedirs(output_path.parent, exist_ok=True)\n",
    "\n",
    "pd.DataFrame(records).to_csv(\n",
    "    output_path,\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 10 Tokens of Features x W_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "\n",
    "llm = LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"cpu\", dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_token_records = {\n",
    "    \"Lang\": [],\n",
    "    \"Layer\": [],\n",
    "    \"Feature ID\": [],\n",
    "    \"Top Tokens\": [],\n",
    "}\n",
    "\n",
    "for lang, layer_final_indices in lang_to_sae_features.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    for layer_idx, final_indices in enumerate(layer_final_indices[\"final_indices\"]):\n",
    "        layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "\n",
    "        # Get the feature vectors for this language and layer\n",
    "        feature_vectors = layer_final_indices[\"stacked_sae_features\"][layer_idx]\n",
    "\n",
    "        if len(feature_vectors) == 0:\n",
    "            continue\n",
    "\n",
    "        # Feed the feature vectors through the lm_head to get token logits\n",
    "        with torch.no_grad():\n",
    "            norm = llm.model.norm(torch.tensor(feature_vectors))\n",
    "            logits = llm.lm_head(norm)\n",
    "\n",
    "        # Get the top 20 tokens for each feature vector\n",
    "        top_token_indices = torch.topk(logits, 10, dim=-1).indices\n",
    "\n",
    "        # Print the language, layer, and top tokens for each feature\n",
    "        for i, feature_idx in enumerate(feature_vectors):\n",
    "            top_tokens = top_token_indices[i].tolist()\n",
    "            token_strings = [llm.tokenizer.decode([idx]) for idx in top_tokens]\n",
    "            token_display = token_strings\n",
    "\n",
    "            top_token_records[\"Lang\"].append(lang)\n",
    "            top_token_records[\"Layer\"].append(layer_str)\n",
    "            top_token_records[\"Feature ID\"].append(final_indices[i])\n",
    "            top_token_records[\"Top Tokens\"].append(token_display)\n",
    "\n",
    "top_token_df = pd.DataFrame(top_token_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "try:\n",
    "    model_path = \"lid.176.bin\"\n",
    "    lang_model = fasttext.load_model(model_path)\n",
    "except:\n",
    "    import urllib.request\n",
    "\n",
    "    url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\"\n",
    "    local_path = Path(\"lid.176.bin\")\n",
    "\n",
    "    if not local_path.exists():\n",
    "        urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "    lang_model = fasttext.load_model(str(local_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_is_language(token, lang):\n",
    "    candidate_languages, _ = lang_model.predict(token.replace(\"\\n\", \"\"), k=1)\n",
    "    iso_code_lang = lang_choices_to_iso639_1[lang]\n",
    "\n",
    "    return f\"__label__{iso_code_lang}\" in candidate_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_language_excel(top_token_df, output_filename=\"language_feature_tokens.xlsx\"):\n",
    "    if not isinstance(top_token_df, pd.DataFrame):\n",
    "        print(\"Error: Input 'top_token_df' must be a pandas DataFrame.\")\n",
    "        return\n",
    "\n",
    "    required_columns = [\"Lang\", \"Layer\", \"Feature ID\", \"Top Tokens\"]\n",
    "    if not all(col in top_token_df.columns for col in required_columns):\n",
    "        print(\n",
    "            f\"Error: DataFrame must contain the following columns: {required_columns}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "        with pd.ExcelWriter(output_filename, engine=\"xlsxwriter\") as writer:\n",
    "            # Get unique languages and sort them for consistent sheet order\n",
    "            if \"sorted_lang\" in top_token_df.columns:\n",
    "                unique_langs = sorted(top_token_df[\"Lang\"].unique())\n",
    "            else:\n",
    "                unique_langs = sorted(top_token_df[\"Lang\"].unique())\n",
    "\n",
    "            for lang in unique_langs:\n",
    "                # Filter DataFrame for the current language\n",
    "                lang_df = top_token_df[top_token_df[\"Lang\"] == lang].copy()\n",
    "\n",
    "                if lang_df.empty:\n",
    "                    print(\n",
    "                        f\"No data found for language: {lang}. Skipping sheet creation.\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Ensure the columns are in the desired order for the Excel sheet:\n",
    "                df_to_write = lang_df[[\"Layer\", \"Lang\", \"Feature ID\", \"Top Tokens\"]]\n",
    "\n",
    "                # Sanitize sheet name\n",
    "                sheet_name = str(lang)\n",
    "                invalid_chars = [\"[\", \"]\", \"*\", \"?\", \":\", \"/\"]\n",
    "                for char in invalid_chars:\n",
    "                    sheet_name = sheet_name.replace(char, \"_\")\n",
    "                if len(sheet_name) > 31:\n",
    "                    sheet_name = sheet_name[:31]\n",
    "\n",
    "                # Write the dataframe to a new sheet. Pandas writes data and default headers.\n",
    "                df_to_write.to_excel(\n",
    "                    writer, sheet_name=sheet_name, index=False, startrow=0\n",
    "                )\n",
    "\n",
    "                # Get the xlsxwriter workbook and worksheet objects.\n",
    "                workbook = writer.book\n",
    "                worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "                # --- Define Formats ---\n",
    "                # Header format (bold, centered, border)\n",
    "                header_format = workbook.add_format(\n",
    "                    {\n",
    "                        \"bold\": True,\n",
    "                        \"align\": \"center\",\n",
    "                        \"valign\": \"vcenter\",\n",
    "                        \"border\": 1,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Format for 'Layer', 'Lang', 'Feature ID' data cells (centered, bordered)\n",
    "                data_center_bordered_format = workbook.add_format(\n",
    "                    {\n",
    "                        \"align\": \"center\",\n",
    "                        \"valign\": \"vcenter\",\n",
    "                        \"border\": 1,  # Apply border to all data cells in these columns\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Format for 'Top Tokens' data cells (wrap text, top-aligned, bordered)\n",
    "                data_wrap_bordered_format = workbook.add_format(\n",
    "                    {\n",
    "                        \"text_wrap\": True,\n",
    "                        \"valign\": \"top\",\n",
    "                        \"border\": 1,  # Apply border to all data cells in this column\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # --- Apply Column Widths ---\n",
    "                worksheet.set_column(\"A:A\", 17.56)  # Layer\n",
    "                worksheet.set_column(\"B:B\", 8.67)  # Lang\n",
    "                worksheet.set_column(\"C:C\", 11.89)  # Feature ID\n",
    "                worksheet.set_column(\"D:D\", 60)  # Top Tokens\n",
    "\n",
    "                # --- Apply Border Only to Header and Filled Rows ---\n",
    "                n_rows = len(df_to_write)\n",
    "                # Write header with border\n",
    "                for col_num, value in enumerate(df_to_write.columns.values):\n",
    "                    worksheet.write(0, col_num, value, header_format)\n",
    "                # Write data with border\n",
    "                for row in range(n_rows):\n",
    "                    worksheet.write(\n",
    "                        row + 1,\n",
    "                        0,\n",
    "                        df_to_write.iloc[row, 0],\n",
    "                        data_center_bordered_format,\n",
    "                    )\n",
    "                    worksheet.write(\n",
    "                        row + 1,\n",
    "                        1,\n",
    "                        df_to_write.iloc[row, 1],\n",
    "                        data_center_bordered_format,\n",
    "                    )\n",
    "                    worksheet.write(\n",
    "                        row + 1,\n",
    "                        2,\n",
    "                        df_to_write.iloc[row, 2],\n",
    "                        data_center_bordered_format,\n",
    "                    )\n",
    "\n",
    "                    top_tokens = []\n",
    "\n",
    "                    # Format tokens in 'Top Tokens' column\n",
    "                    bold_format = workbook.add_format({\"bold\": True})\n",
    "\n",
    "                    for token in df_to_write.iloc[row, 3]:\n",
    "                        if token_is_language(token, lang):\n",
    "                            top_tokens.append(bold_format)\n",
    "                            top_tokens.append(token)\n",
    "                            top_tokens.append(\", \")\n",
    "                        else:\n",
    "                            top_tokens.append(token)\n",
    "                            top_tokens.append(\", \")\n",
    "\n",
    "                    top_tokens = top_tokens[:-1]  # Remove the last comma\n",
    "                    worksheet.write_rich_string(\n",
    "                        row + 1, 3, *top_tokens, data_wrap_bordered_format\n",
    "                    )\n",
    "\n",
    "        print(\n",
    "            f\"Excel file '{output_filename}' created successfully. Borders applied only to header and filled rows of each sheet.\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "output_path = (\n",
    "    project_dir\n",
    "    / \"top_token_features\"\n",
    "    / config_xnli[\"model\"]\n",
    "    / config_xnli[\"sae\"][\"model\"]\n",
    "    / \"top_token_features.xlsx\"\n",
    ")\n",
    "\n",
    "os.makedirs(output_path.parent, exist_ok=True)\n",
    "\n",
    "# NOTE: the generated excel must be refined\n",
    "create_language_excel(top_token_df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang, layer_final_indices in lang_to_sae_features.items():\n",
    "    print(f\"Language: {lang}\")\n",
    "    for layer_idx, final_indices in enumerate(layer_final_indices[\"final_indices\"]):\n",
    "        layer_str = f\"layers.{layer_idx}.mlp\"\n",
    "        bias_vector = sae_vectors[layer_str][\"bias\"]\n",
    "\n",
    "        # Get the feature vectors for this language and layer\n",
    "        feature_vectors = layer_final_indices[\"stacked_sae_features\"][layer_idx]\n",
    "\n",
    "        if len(feature_vectors) == 0:\n",
    "            continue\n",
    "\n",
    "        # Feed the feature vectors through the lm_head to get token logits\n",
    "        with torch.no_grad():\n",
    "            norm = llm.model.norm(torch.tensor(feature_vectors).sum(dim=0))\n",
    "            logits = llm.lm_head(norm)\n",
    "\n",
    "        # Get the top 20 tokens for each feature vector\n",
    "        top_token_indices = torch.topk(logits, 10, dim=-1).indices\n",
    "\n",
    "        # Print the language, layer, and top tokens for each feature\n",
    "        top_tokens = top_token_indices.tolist()\n",
    "        token_strings = [llm.tokenizer.decode([idx]) for idx in top_tokens]\n",
    "        token_display = \", \".join([f\"{token}\" for token in token_strings])\n",
    "        print(f\"Layer: {layer_str}\")\n",
    "        print(f\"  Top tokens: {token_display}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropies and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_features_info = load_sae_features_info_df(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"correlation\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    ")\n",
    "\n",
    "plot_sae_features_entropy_score_correlation(\n",
    "    sae_features_info,\n",
    "    output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"entropy\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    ")\n",
    "\n",
    "plot_entropy_distribution(\n",
    "    sae_features_info,\n",
    "    output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Language-Specific Features Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_sae_features_info = load_lang_to_sae_features_info(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    interpretations,\n",
    "    metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = project_dir / \"interpret_sae_features\" / \"language_specific_features\"\n",
    "\n",
    "with open(output_dir / \"lang_to_sae_features_info.json\", \"w\") as f:\n",
    "    json.dump(lang_to_sae_features_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_sae_features_info_extra = load_lang_to_sae_features_info(\n",
    "    lape_all_result,\n",
    "    config_flores[\"layers\"],\n",
    "    interpretations,\n",
    "    metrics,\n",
    "    extra=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = project_dir / \"interpret_sae_features\" / \"language_specific_features\"\n",
    "\n",
    "with open(output_dir / \"lang_to_sae_features_info_extra.json\", \"w\") as f:\n",
    "    json.dump(lang_to_sae_features_info_extra, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "workbook = xlsxwriter.Workbook(output_dir / \"lang_to_sae_features_info_extra.xlsx\")\n",
    "\n",
    "# Define cell formats\n",
    "header_format = workbook.add_format(\n",
    "    {\n",
    "        \"bold\": True,\n",
    "        \"text_wrap\": True,\n",
    "        \"valign\": \"vcenter\",\n",
    "        \"align\": \"center\",\n",
    "        \"border\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "center_aligned_format = workbook.add_format(\n",
    "    {\n",
    "        \"align\": \"center\",\n",
    "        \"valign\": \"vcenter\",\n",
    "        \"border\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "left_wrap_format = workbook.add_format(\n",
    "    {\n",
    "        \"align\": \"left\",\n",
    "        \"valign\": \"vcenter\",\n",
    "        \"text_wrap\": True,\n",
    "        \"border\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Iterate over each language in the JSON data\n",
    "for lang_name, layers_data in lang_to_sae_features_info_extra.items():\n",
    "    # Add a new worksheet for each language. Sheet names have a max length of 31.\n",
    "    worksheet_name = lang_name if len(lang_name) < 32 else lang_name[:31]\n",
    "    worksheet = workbook.add_worksheet(worksheet_name)\n",
    "\n",
    "    # Set column widths\n",
    "    worksheet.set_column(\"A:A\", 17.56)  # Layer\n",
    "    worksheet.set_column(\"B:B\", 8.67)  # Lang\n",
    "    worksheet.set_column(\"C:C\", 11.89)  # Feature ID\n",
    "    worksheet.set_column(\"D:D\", 52.22)  # Interpretation\n",
    "    worksheet.set_column(\"E:H\", 8)  # Detection metrics\n",
    "    worksheet.set_column(\"I:L\", 8)  # Fuzzing metrics\n",
    "\n",
    "    # Write headers\n",
    "    # Row 1: Main Headers\n",
    "    worksheet.merge_range(\"A1:A2\", \"Layer\", header_format)\n",
    "    worksheet.merge_range(\"B1:B2\", \"Lang\", header_format)\n",
    "    worksheet.merge_range(\"C1:C2\", \"Feature ID\", header_format)\n",
    "    worksheet.merge_range(\"D1:D2\", \"Interpretation\", header_format)\n",
    "\n",
    "    # Merged cells for Detection and Fuzzing\n",
    "    worksheet.merge_range(\"E1:H1\", \"Detection\", header_format)\n",
    "    worksheet.merge_range(\"I1:L1\", \"Fuzzing\", header_format)\n",
    "\n",
    "    # Row 2: Sub-headers for metrics\n",
    "    metric_sub_headers = [\"Accuracy\", \"F1 score\", \"Precision\", \"Recall\"]\n",
    "    detection_start_col = 4  # Column E\n",
    "    fuzzing_start_col = 8  # Column I\n",
    "\n",
    "    for i, sub_header in enumerate(metric_sub_headers):\n",
    "        worksheet.write(1, detection_start_col + i, sub_header, header_format)\n",
    "        worksheet.write(1, fuzzing_start_col + i, sub_header, header_format)\n",
    "\n",
    "    # Start writing data from the third row (index 2)\n",
    "    current_row = 2\n",
    "    for layer_key, feature_id_dict in layers_data.items():\n",
    "        for fid_key, details in feature_id_dict.items():\n",
    "            # Extract basic info\n",
    "            layer_val = details.get(\"Layer\", \"\")\n",
    "            lang_val = details.get(\"Lang\", \"\")\n",
    "            feature_id_val = details.get(\"Feature ID\", \"\")\n",
    "            interpretation_val = details.get(\"Interpretation\", \"\")\n",
    "            # Remove surrounding quotes from interpretation if they exist due to json dump\n",
    "            if interpretation_val.startswith('\"') and interpretation_val.endswith('\"'):\n",
    "                interpretation_val = interpretation_val[1:-1]\n",
    "\n",
    "            # Extract metrics\n",
    "            detection_metrics = {}\n",
    "            fuzz_metrics = {}\n",
    "            for metric_set in details.get(\"Metrics\", []):\n",
    "                if metric_set.get(\"score_type\") == \"detection\":\n",
    "                    detection_metrics = {\n",
    "                        \"accuracy\": metric_set.get(\"accuracy\"),\n",
    "                        \"f1_score\": metric_set.get(\"f1_score\"),\n",
    "                        \"precision\": metric_set.get(\"precision\"),\n",
    "                        \"recall\": metric_set.get(\"recall\"),\n",
    "                    }\n",
    "                elif metric_set.get(\"score_type\") == \"fuzz\":\n",
    "                    fuzz_metrics = {\n",
    "                        \"accuracy\": metric_set.get(\"accuracy\"),\n",
    "                        \"f1_score\": metric_set.get(\"f1_score\"),\n",
    "                        \"precision\": metric_set.get(\"precision\"),\n",
    "                        \"recall\": metric_set.get(\"recall\"),\n",
    "                    }\n",
    "\n",
    "            # Write data to cells with specified formats\n",
    "            worksheet.write(current_row, 0, layer_val, center_aligned_format)\n",
    "            worksheet.write(current_row, 1, lang_val, center_aligned_format)\n",
    "            worksheet.write(current_row, 2, feature_id_val, center_aligned_format)\n",
    "            worksheet.write(current_row, 3, interpretation_val, left_wrap_format)\n",
    "\n",
    "            # Write Detection metrics\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 0,\n",
    "                detection_metrics.get(\"accuracy\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 1,\n",
    "                detection_metrics.get(\"f1_score\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 2,\n",
    "                detection_metrics.get(\"precision\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                detection_start_col + 3,\n",
    "                detection_metrics.get(\"recall\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "\n",
    "            # Write Fuzzing metrics\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 0,\n",
    "                fuzz_metrics.get(\"accuracy\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 1,\n",
    "                fuzz_metrics.get(\"f1_score\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 2,\n",
    "                fuzz_metrics.get(\"precision\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "            worksheet.write(\n",
    "                current_row,\n",
    "                fuzzing_start_col + 3,\n",
    "                fuzz_metrics.get(\"recall\"),\n",
    "                center_aligned_format,\n",
    "            )\n",
    "\n",
    "            current_row += 1\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langauage-Shared Features Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shared-Feature Intersection and Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_to_count_final_indicies = {}\n",
    "\n",
    "for shared_count in range(2, len(config_flores[\"languages\"]) + 1):\n",
    "    lape_shared_path = (\n",
    "        project_dir\n",
    "        / \"sae_features_shared\"\n",
    "        / config_xnli[\"model\"]\n",
    "        / config_xnli[\"sae\"][\"model\"]\n",
    "        / f\"lape_shared_{shared_count}.pt\"\n",
    "    )\n",
    "\n",
    "    lape_shared_result = torch.load(lape_shared_path)\n",
    "\n",
    "    sorted_lang = lape_shared_result[\"sorted_lang\"]\n",
    "\n",
    "    for lang in sorted_lang:\n",
    "        if lang not in lape_shared_result[\"features_info\"]:\n",
    "            print(\n",
    "                f\"Language {lang} not found in features_info for shared count {shared_count}.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        lang_indices = lape_shared_result[\"features_info\"][lang][\"indicies\"]\n",
    "\n",
    "        if lang not in lang_to_count_final_indicies:\n",
    "            lang_to_count_final_indicies[lang] = set()\n",
    "\n",
    "        lang_to_count_final_indicies[lang].update(lang_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"shared_features\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / \"feature_intersection_heatmap.html\"\n",
    ")\n",
    "\n",
    "plot_intersection_heatmap(lang_to_count_final_indicies, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"shared_features\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / \"iou_heatmap.html\"\n",
    ")\n",
    "\n",
    "\n",
    "plot_iou_heatmap(lang_to_count_final_indicies, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shared-Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_final_indicies = {}\n",
    "\n",
    "for shared_count in range(2, len(config_flores[\"languages\"]) + 1):\n",
    "    lape_shared_path = (\n",
    "        project_dir\n",
    "        / \"sae_features_shared\"\n",
    "        / config_xnli[\"model\"]\n",
    "        / config_xnli[\"sae\"][\"model\"]\n",
    "        / f\"lape_shared_{shared_count}.pt\"\n",
    "    )\n",
    "\n",
    "    lape_shared_result = torch.load(lape_shared_path)\n",
    "\n",
    "    sorted_lang = lape_shared_result[\"sorted_lang\"]\n",
    "\n",
    "    for lang in sorted_lang:\n",
    "        if lang not in lape_shared_result[\"features_info\"]:\n",
    "            print(\n",
    "                f\"Language {lang} not found in features_info for shared count {shared_count}.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        lang_indices = lape_shared_result[\"features_info\"][lang][\"indicies\"]\n",
    "\n",
    "        if shared_count not in count_final_indicies:\n",
    "            count_final_indicies[shared_count] = set()\n",
    "\n",
    "        count_final_indicies[shared_count].update(lang_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"shared_features\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / \"feature_distribution.html\"\n",
    ")\n",
    "\n",
    "plot_shared_count_bar_chart(count_final_indicies, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_final_indicies_half_low = {}\n",
    "count_final_indicies_half_high = {}\n",
    "\n",
    "half_low_indices = [2, 3, 4, 5, 6, 7, 8]\n",
    "half_high_indices = [9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "for half_low_index in half_low_indices:\n",
    "    count_final_indicies_half_low[half_low_index] = count_final_indicies[half_low_index]\n",
    "\n",
    "for half_high_index in half_high_indices:\n",
    "    count_final_indicies_half_high[half_high_index] = count_final_indicies[\n",
    "        half_high_index\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"shared_features\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / \"feature_distribution_half_low.html\"\n",
    ")\n",
    "\n",
    "plot_shared_count_bar_chart(count_final_indicies_half_low, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = (\n",
    "    project_dir\n",
    "    / \"visualization\"\n",
    "    / \"shared_features\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"sae\"][\"model\"]\n",
    "    / \"feature_distribution_half_high.html\"\n",
    ")\n",
    "\n",
    "plot_shared_count_bar_chart(count_final_indicies_half_high, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PPL Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_ppl_output_path = (\n",
    "    project_dir\n",
    "    / \"ppl\"\n",
    "    / config_flores[\"model\"]\n",
    "    / config_flores[\"dataset\"]\n",
    "    / \"normal\"\n",
    "    / \"ppl.pt\"\n",
    ")\n",
    "\n",
    "normal_ppl_result = torch.load(normal_ppl_output_path, weights_only=False)\n",
    "\n",
    "config_lang_to_ppl_avg_ppl = {\n",
    "    \"normal\": {\n",
    "        lang: round(normal_ppl_result[lang][\"mean_perplexity\"], 2)\n",
    "        for lang in normal_ppl_result\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_lang_to_ppl_avg_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_features_ppl_output_path_list = [\n",
    "    Path(\n",
    "        r\"ppl/meta-llama/Llama-3.2-1B/openlanguagedata/flores_plus/shared_features/entropy/max/mult_-0.2\"\n",
    "    ),\n",
    "    Path(\n",
    "        r\"ppl/meta-llama/Llama-3.2-1B/openlanguagedata/flores_plus/shared_features/entropy/max/mult_-0.3\"\n",
    "    ),\n",
    "    Path(\n",
    "        r\"ppl/meta-llama/Llama-3.2-1B/openlanguagedata/flores_plus/shared_features/entropy/max/mult_-0.4\"\n",
    "    ),\n",
    "    Path(\n",
    "        r\"ppl/meta-llama/Llama-3.2-1B/openlanguagedata/flores_plus/shared_features/entropy/max/mult_0.2\"\n",
    "    ),\n",
    "    Path(\n",
    "        r\"ppl/meta-llama/Llama-3.2-1B/openlanguagedata/flores_plus/shared_features/entropy/max/mult_0.3\"\n",
    "    ),\n",
    "    Path(\n",
    "        r\"ppl/meta-llama/Llama-3.2-1B/openlanguagedata/flores_plus/shared_features/entropy/max/mult_0.4\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "shared_features_ppl_to_result = {\n",
    "    path.name: torch.load(project_dir / path / \"ppl.pt\", weights_only=False)\n",
    "    for path in shared_features_ppl_output_path_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config, ppl_results in shared_features_ppl_to_result.items():\n",
    "    langs = list(ppl_results.keys())\n",
    "\n",
    "    for intervened_lang_index, intervened_lang in enumerate(langs):\n",
    "\n",
    "        if config not in config_lang_to_ppl_avg_ppl:\n",
    "            config_lang_to_ppl_avg_ppl[config] = {}\n",
    "\n",
    "        config_lang_to_ppl_avg_ppl[config][intervened_lang] = round(\n",
    "            ppl_results[intervened_lang][\"mean_perplexity\"], 2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(config_lang_to_ppl_avg_ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
