# Note:
# Llama-3.2-1B officially supports English (en), German (de), French (fr), Italian (it), Portuguese (pt), Hindi (hi), Spanish (es), and Thai (th)
# Additionally, add Bulgarian (bg), Russian (ru), Turkish (tr), and Vietnamese (vi) because they have accuracy above 40% on the XNLI task based on `llama3.2_eval.ipynb`
# Add Japanese (ja), Korean (ko), and Chinese (zh) for PAWS-X task
lang_choices = [
    "en",
    "de",
    "fr",
    "it",
    "pt",
    "hi",
    "es",
    "th",
    "bg",
    "ru",
    "tr",
    "vi",
    "ja",
    "ko",
    "zh",
]

flore_plus_lang_choices = [
    "eng_Latn",
    "deu_Latn",
    "fra_Latn",
    "ita_Latn",
    "por_Latn",
    "hin_Deva",
    "spa_Latn",
    "tha_Thai",
    "bul_Cyrl",
    "rus_Cyrl",
    "tur_Latn",
    "vie_Latn",
    "jpn_Jpan",
    "kor_Hang",
    "cmn_Hans",
]

iso639_2_lang_choices = [
    "eng",
    "deu",
    "fra",
    "ita",
    "por",
    "hin",
    "spa",
    "tha",
    "bul",
    "rus",
    "tur",
    "vie",
    "jpn",
    "kor",
    "zho",
]

lang_choices = [
    *lang_choices,
    *flore_plus_lang_choices,
    *iso639_2_lang_choices,
]

lang_choices_to_qualified_name = {
    "en": "English",
    "de": "German",
    "fr": "French",
    "it": "Italian",
    "pt": "Portuguese",
    "hi": "Hindi",
    "es": "Spanish",
    "th": "Thai",
    "bg": "Bulgarian",
    "ru": "Russian",
    "tr": "Turkish",
    "vi": "Vietnamese",
    "ja": "Japanese",
    "ko": "Korean",
    "zh": "Chinese",
    "eng_Latn": "English",
    "deu_Latn": "German",
    "fra_Latn": "French",
    "ita_Latn": "Italian",
    "por_Latn": "Portuguese",
    "hin_Deva": "Hindi",
    "spa_Latn": "Spanish",
    "tha_Thai": "Thai",
    "bul_Cyrl": "Bulgarian",
    "rus_Cyrl": "Russian",
    "tur_Latn": "Turkish",
    "vie_Latn": "Vietnamese",
    "jpn_Jpan": "Japanese",
    "kor_Hang": "Korean",
    "cmn_Hans": "Chinese",
    "eng": "English",
    "deu": "German",
    "fra": "French",
    "ita": "Italian",
    "por": "Portuguese",
    "hin": "Hindi",
    "spa": "Spanish",
    "tha": "Thai",
    "bul": "Bulgarian",
    "rus": "Russian",
    "tur": "Turkish",
    "vie": "Vietnamese",
    "jpn": "Japanese",
    "kor": "Korean",
    "cmn": "Chinese",
}

lang_choices_to_iso639_1 = {
    "en": "en",
    "de": "de",
    "fr": "fr",
    "it": "it",
    "pt": "pt",
    "hi": "hi",
    "es": "es",
    "th": "th",
    "bg": "bg",
    "ru": "ru",
    "tr": "tr",
    "vi": "vi",
    "ja": "ja",
    "ko": "ko",
    "zh": "zh",
    "eng_Latn": "en",
    "deu_Latn": "de",
    "fra_Latn": "fr",
    "ita_Latn": "it",
    "por_Latn": "pt",
    "hin_Deva": "hi",
    "spa_Latn": "es",
    "tha_Thai": "th",
    "bul_Cyrl": "bg",
    "rus_Cyrl": "ru",
    "tur_Latn": "tr",
    "vie_Latn": "vi",
    "jpn_Jpan": "ja",
    "kor_Hang": "ko",
    "cmn_Hans": "zh",
    "eng": "en",
    "deu": "de",
    "fra": "fr",
    "ita": "it",
    "por": "pt",
    "hin": "hi",
    "spa": "es",
    "tha": "th",
    "bul": "bg",
    "rus": "ru",
    "tur": "tr",
    "vie": "vi",
    "jpn": "ja",
    "kor": "ko",
    "cmn": "zh",
    "zho": "zh",
    "English": "en",
    "German": "de",
    "French": "fr",
    "Italian": "it",
    "Portuguese": "pt",
    "Hindi": "hi",
    "Spanish": "es",
    "Thai": "th",
    "Bulgarian": "bg",
    "Russian": "ru",
    "Turkish": "tr",
    "Vietnamese": "vi",
    "Japanese": "ja",
    "Korean": "ko",
    "Chinese": "zh",
}

lang_choices_to_iso639_2 = {
    "en": "eng",
    "de": "deu",
    "fr": "fra",
    "it": "ita",
    "pt": "por",
    "hi": "hin",
    "es": "spa",
    "th": "tha",
    "bg": "bul",
    "ru": "rus",
    "tr": "tur",
    "vi": "vie",
    "ja": "jpn",
    "ko": "kor",
    "zh": "zho",
    "eng_Latn": "eng",
    "deu_Latn": "deu",
    "fra_Latn": "fra",
    "ita_Latn": "ita",
    "por_Latn": "por",
    "hin_Deva": "hin",
    "spa_Latn": "spa",
    "tha_Thai": "tha",
    "bul_Cyrl": "bul",
    "rus_Cyrl": "rus",
    "tur_Latn": "tur",
    "vie_Latn": "vie",
    "jpn_Jpan": "jpn",
    "kor_Hang": "kor",
    "cmn_Hans": "zho",
    "eng": "eng",
    "deu": "deu",
    "fra": "fra",
    "ita": "ita",
    "por": "por",
    "hin": "hin",
    "spa": "spa",
    "tha": "tha",
    "bul": "bul",
    "rus": "rus",
    "tur": "tur",
    "vie": "vie",
    "jpn": "jpn",
    "kor": "kor",
    "cmn": "zho",
    "English": "eng",
    "German": "deu",
    "French": "fra",
    "Italian": "ita",
    "Portuguese": "por",
    "Hindi": "hin",
    "Spanish": "spa",
    "Thai": "tha",
    "Bulgarian": "bul",
    "Russian": "rus",
    "Turkish": "tur",
    "Vietnamese": "vie",
    "Japanese": "jpn",
    "Korean": "kor",
    "Chinese": "zho",
}

lang_choices_to_flores = {
    "en": "eng_Latn",
    "de": "deu_Latn",
    "fr": "fra_Latn",
    "it": "ita_Latn",
    "pt": "por_Latn",
    "hi": "hin_Deva",
    "es": "spa_Latn",
    "th": "tha_Thai",
    "bg": "bul_Cyrl",
    "ru": "rus_Cyrl",
    "tr": "tur_Latn",
    "vi": "vie_Latn",
    "ja": "jpn_Jpan",
    "ko": "kor_Hang",
    "zh": "cmn_Hans",
    "eng_Latn": "eng_Latn",
    "deu_Latn": "deu_Latn",
    "fra_Latn": "fra_Latn",
    "ita_Latn": "ita_Latn",
    "por_Latn": "por_Latn",
    "hin_Deva": "hin_Deva",
    "spa_Latn": "spa_Latn",
    "tha_Thai": "tha_Thai",
    "bul_Cyrl": "bul_Cyrl",
    "rus_Cyrl": "rus_Cyrl",
    "tur_Latn": "tur_Latn",
    "vie_Latn": "vie_Latn",
    "jpn_Jpan": "jpn_Jpan",
    "kor_Hang": "kor_Hang",
    "cmn_Hans": "cmn_Hans",
    "eng": "eng_Latn",
    "deu": "deu_Latn",
    "fra": "fra_Latn",
    "ita": "ita_Latn",
    "por": "por_Latn",
    "hin": "hin_Deva",
    "spa": "spa_Latn",
    "tha": "tha_Thai",
    "bul": "bul_Cyrl",
    "rus": "rus_Cyrl",
    "tur": "tur_Latn",
    "vie": "vie_Latn",
    "jpn": "jpn_Jpan",
    "kor": "kor_Hang",
    "cmn": "cmn_Hans",
    "English": "eng_Latn",
    "German": "deu_Latn",
    "French": "fra_Latn",
    "Italian": "ita_Latn",
    "Portuguese": "por_Latn",
    "Hindi": "hin_Deva",
    "Spanish": "spa_Latn",
    "Thai": "tha_Thai",
    "Bulgarian": "bul_Cyrl",
    "Russian": "rus_Cyrl",
    "Turkish": "tur_Latn",
    "Vietnamese": "vie_Latn",
    "Japanese": "jpn_Jpan",
    "Korean": "kor_Hang",
    "Chinese": "cmn_Hans",
}

language_colors = {
    "bg": "#fd3216",
    "zh": "#00fe35",
    "en": "#6a76fc",
    "fr": "#fed4c4",
    "de": "#fe00ce",
    "hi": "#0df9ff",
    "it": "#f6f926",
    "jp": "#ff9616",
    "ko": "#479b55",
    "pt": "#eea6fb",
    "ru": "#dc587d",
    "es": "#d626ff",
    "th": "#6e899c",
    "tr": "#00b5f7",
    "vi": "#b68e00",
}

model_choices = [
    "meta-llama/Llama-3.2-1B",
    "google/gemma-2-2b",
    "google/gemma-2-9b",
]

dataset_choices = [
    "facebook/xnli",
    "google-research-datasets/paws-x",
    "openlanguagedata/flores_plus",
    "MartinThoma/wili_2018",
]

prompt_templates = {
    "facebook/xnli": {
        "en": "{premise} {hypothesis}",
        "de": "{premise} {hypothesis}",
        "fr": "{premise} {hypothesis}",
        "hi": "{premise} {hypothesis}",
        "es": "{premise} {hypothesis}",
        "th": "{premise} {hypothesis}",
        "bg": "{premise} {hypothesis}",
        "ru": "{premise} {hypothesis}",
        "tr": "{premise} {hypothesis}",
        "vi": "{premise} {hypothesis}",
    },
    "google-research-datasets/paws-x": {
        "en": "{sentence1}",
        "de": "{sentence1}",
        "fr": "{sentence1}",
        "es": "{sentence1}",
        "ja": "{sentence1}",
        "ko": "{sentence1}",
        "zh": "{sentence1}",
    },
    "openlanguagedata/flores_plus": {
        "eng_Latn": "{text}",
        "deu_Latn": "{text}",
        "fra_Latn": "{text}",
        "ita_Latn": "{text}",
        "por_Latn": "{text}",
        "hin_Deva": "{text}",
        "spa_Latn": "{text}",
        "tha_Thai": "{text}",
        "bul_Cyrl": "{text}",
        "rus_Cyrl": "{text}",
        "tur_Latn": "{text}",
        "vie_Latn": "{text}",
        "jpn_Jpan": "{text}",
        "kor_Hang": "{text}",
        "cmn_Hans": "{text}",
    },
    "MartinThoma/wili_2018": {
        "eng": "{sentence}",
        "deu": "{sentence}",
        "fra": "{sentence}",
        "ita": "{sentence}",
        "por": "{sentence}",
        "hin": "{sentence}",
        "spa": "{sentence}",
        "tha": "{sentence}",
        "bul": "{sentence}",
        "rus": "{sentence}",
        "tur": "{sentence}",
        "vie": "{sentence}",
        "jpn": "{sentence}",
        "kor": "{sentence}",
        "zho": "{sentence}",
    },
}

sae_model_choices = [
    "EleutherAI/sae-Llama-3.2-1B-131k",
    "EleutherAI/sae",  # Local SAE
    "google/gemma-scope-2b-pt-res",
    "google/gemma-scope-2b-pt-res-canonical",
    "google/gemma-scope-2b-pt-mlp",
    "google/gemma-scope-2b-pt-mlp-canonical",
    "google/gemma-scope-2b-pt-att",
    "google/gemma-scope-9b-pt-att-canonical",
    "google/gemma-scope-9b-pt-res",
    "google/gemma-scope-9b-pt-res-canonical",
    "google/gemma-scope-9b-pt-mlp",
    "google/gemma-scope-9b-pt-mlp-canonical",
    "google/gemma-scope-9b-pt-att",
    "google/gemma-scope-9b-pt-att-canonical",
]

sae_model_layer_to_hookpoint = {
    "meta-llama/Llama-3.2-1B": {
        "EleutherAI/sae-Llama-3.2-1B-131k": {
            "model.layers.0.mlp": "layers.0.mlp",
            "model.layers.1.mlp": "layers.1.mlp",
            "model.layers.2.mlp": "layers.2.mlp",
            "model.layers.3.mlp": "layers.3.mlp",
            "model.layers.4.mlp": "layers.4.mlp",
            "model.layers.5.mlp": "layers.5.mlp",
            "model.layers.6.mlp": "layers.6.mlp",
            "model.layers.7.mlp": "layers.7.mlp",
            "model.layers.8.mlp": "layers.8.mlp",
            "model.layers.9.mlp": "layers.9.mlp",
            "model.layers.10.mlp": "layers.10.mlp",
            "model.layers.11.mlp": "layers.11.mlp",
            "model.layers.12.mlp": "layers.12.mlp",
            "model.layers.13.mlp": "layers.13.mlp",
            "model.layers.14.mlp": "layers.14.mlp",
            "model.layers.15.mlp": "layers.15.mlp",
        },
        # Custom SAE model for Llama-3.2-1B
        "EleutherAI/sae": {
            "model.layers.0.mlp": "layers.0.mlp",
            "model.layers.1.mlp": "layers.1.mlp",
            "model.layers.2.mlp": "layers.2.mlp",
            "model.layers.3.mlp": "layers.3.mlp",
            "model.layers.4.mlp": "layers.4.mlp",
            "model.layers.5.mlp": "layers.5.mlp",
            "model.layers.6.mlp": "layers.6.mlp",
            "model.layers.7.mlp": "layers.7.mlp",
            "model.layers.8.mlp": "layers.8.mlp",
            "model.layers.9.mlp": "layers.9.mlp",
            "model.layers.10.mlp": "layers.10.mlp",
            "model.layers.11.mlp": "layers.11.mlp",
            "model.layers.12.mlp": "layers.12.mlp",
            "model.layers.13.mlp": "layers.13.mlp",
            "model.layers.14.mlp": "layers.14.mlp",
            "model.layers.15.mlp": "layers.15.mlp",
        },
    },
}

hookpoint_to_layer = {
    "layers.0.mlp": 0,
    "layers.1.mlp": 1,
    "layers.2.mlp": 2,
    "layers.3.mlp": 3,
    "layers.4.mlp": 4,
    "layers.5.mlp": 5,
    "layers.6.mlp": 6,
    "layers.7.mlp": 7,
    "layers.8.mlp": 8,
    "layers.9.mlp": 9,
    "layers.10.mlp": 10,
    "layers.11.mlp": 11,
    "layers.12.mlp": 12,
    "layers.13.mlp": 13,
    "layers.14.mlp": 14,
    "layers.15.mlp": 15,
}

mlp_to_index = {
    "model.layers.0.mlp": 0,
    "model.layers.1.mlp": 1,
    "model.layers.2.mlp": 2,
    "model.layers.3.mlp": 3,
    "model.layers.4.mlp": 4,
    "model.layers.5.mlp": 5,
    "model.layers.6.mlp": 6,
    "model.layers.7.mlp": 7,
    "model.layers.8.mlp": 8,
    "model.layers.9.mlp": 9,
    "model.layers.10.mlp": 10,
    "model.layers.11.mlp": 11,
    "model.layers.12.mlp": 12,
    "model.layers.13.mlp": 13,
    "model.layers.14.mlp": 14,
    "model.layers.15.mlp": 15,
}

mlp_acts_to_index = {
    "model.layers.0.mlp.act_fn": 0,
    "model.layers.1.mlp.act_fn": 1,
    "model.layers.2.mlp.act_fn": 2,
    "model.layers.3.mlp.act_fn": 3,
    "model.layers.4.mlp.act_fn": 4,
    "model.layers.5.mlp.act_fn": 5,
    "model.layers.6.mlp.act_fn": 6,
    "model.layers.7.mlp.act_fn": 7,
    "model.layers.8.mlp.act_fn": 8,
    "model.layers.9.mlp.act_fn": 9,
    "model.layers.10.mlp.act_fn": 10,
    "model.layers.11.mlp.act_fn": 11,
    "model.layers.12.mlp.act_fn": 12,
    "model.layers.13.mlp.act_fn": 13,
    "model.layers.14.mlp.act_fn": 14,
    "model.layers.15.mlp.act_fn": 15,
}

layer_to_index = {
    **mlp_to_index,
    **mlp_acts_to_index,
}
